{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deconstructing lottery ticket hypothesis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diptansu/deconstructing-lottery-tickets/blob/master/deconstructing_lottery_ticket_hypothesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGw2REe8SZIi",
        "outputId": "48ca248c-4491-4f74-aff8-5bcf9a3dfdd2"
      },
      "source": [
        "!git clone https://github.com/diptansu/deconstructing-lottery-tickets.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deconstructing-lottery-tickets'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 89 (delta 39), reused 66 (delta 26), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (89/89), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn8GOdrSM5Nb",
        "outputId": "2e2e48be-75fd-44e7-a42d-6da2f95bfa1f"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda=9.0.176-1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-01 03:28:45--  https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 152.199.0.24\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|152.199.0.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb?cST0zMwbZuFT-u5mX555yHm6YlRLP0dbP9KF88kdfCLw9kUd6fRamaPrtWbjERhEQ1H1Srw5ixuFyZIwTXbHiHsP2KqiZi93Q6XbpfgLGrKpk1uMWUnFgvJl3siXMeyyxyTdv0cQVvwxv6WvbcqjbmVzByuonsqQJY1yeSPdb9EhAxbR5mQG5eIblkwYdF02ToOhVg42RoagBg9MEmqA [following]\n",
            "--2020-12-01 03:28:46--  https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb?cST0zMwbZuFT-u5mX555yHm6YlRLP0dbP9KF88kdfCLw9kUd6fRamaPrtWbjERhEQ1H1Srw5ixuFyZIwTXbHiHsP2KqiZi93Q6XbpfgLGrKpk1uMWUnFgvJl3siXMeyyxyTdv0cQVvwxv6WvbcqjbmVzByuonsqQJY1yeSPdb9EhAxbR5mQG5eIblkwYdF02ToOhVg42RoagBg9MEmqA\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1212738714 (1.1G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb’\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   1.13G  87.2MB/s    in 15s     \n",
            "\n",
            "2020-12-01 03:29:01 (77.0 MB/s) - ‘cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb’ saved [1212738714/1212738714]\n",
            "\n",
            "Selecting previously unselected package cuda-repo-ubuntu1604-9-0-local.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb ...\n",
            "Unpacking cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
            "Setting up cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
            "OK\n",
            "Get:1 file:/var/cuda-repo-9-0-local  InRelease\n",
            "Ign:1 file:/var/cuda-repo-9-0-local  InRelease\n",
            "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
            "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 file:/var/cuda-repo-9-0-local  Packages [15.4 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [443 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,691 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,781 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,218 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,366 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [257 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,131 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [865 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [54.3 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [46.5 kB]\n",
            "Fetched 11.1 MB in 3s (4,294 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cuda-9-0 cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
            "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
            "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
            "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
            "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
            "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
            "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
            "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
            "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
            "The following NEW packages will be installed:\n",
            "  cuda cuda-9-0 cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
            "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
            "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
            "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
            "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
            "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
            "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
            "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
            "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
            "0 upgraded, 34 newly installed, 0 to remove and 64 not upgraded.\n",
            "Need to get 0 B/1,097 MB of archives.\n",
            "After this operation, 2,315 MB of additional disk space will be used.\n",
            "Get:1 file:/var/cuda-repo-9-0-local  cuda-license-9-0 9.0.176-1 [22.0 kB]\n",
            "Get:2 file:/var/cuda-repo-9-0-local  cuda-misc-headers-9-0 9.0.176-1 [684 kB]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  cuda-core-9-0 9.0.176-1 [16.9 MB]\n",
            "Get:4 file:/var/cuda-repo-9-0-local  cuda-cudart-9-0 9.0.176-1 [106 kB]\n",
            "Get:5 file:/var/cuda-repo-9-0-local  cuda-driver-dev-9-0 9.0.176-1 [10.9 kB]\n",
            "Get:6 file:/var/cuda-repo-9-0-local  cuda-cudart-dev-9-0 9.0.176-1 [767 kB]\n",
            "Get:7 file:/var/cuda-repo-9-0-local  cuda-command-line-tools-9-0 9.0.176-1 [25.4 MB]\n",
            "Get:8 file:/var/cuda-repo-9-0-local  cuda-nvrtc-9-0 9.0.176-1 [6,348 kB]\n",
            "Get:9 file:/var/cuda-repo-9-0-local  cuda-nvrtc-dev-9-0 9.0.176-1 [9,334 B]\n",
            "Get:10 file:/var/cuda-repo-9-0-local  cuda-cusolver-9-0 9.0.176-1 [26.2 MB]\n",
            "Get:11 file:/var/cuda-repo-9-0-local  cuda-cusolver-dev-9-0 9.0.176-1 [5,317 kB]\n",
            "Get:12 file:/var/cuda-repo-9-0-local  cuda-cublas-9-0 9.0.176-1 [25.0 MB]\n",
            "Get:13 file:/var/cuda-repo-9-0-local  cuda-cublas-dev-9-0 9.0.176-1 [49.4 MB]\n",
            "Get:14 file:/var/cuda-repo-9-0-local  cuda-cufft-9-0 9.0.176-1 [84.1 MB]\n",
            "Get:15 file:/var/cuda-repo-9-0-local  cuda-cufft-dev-9-0 9.0.176-1 [73.7 MB]\n",
            "Get:16 file:/var/cuda-repo-9-0-local  cuda-curand-9-0 9.0.176-1 [38.8 MB]\n",
            "Get:17 file:/var/cuda-repo-9-0-local  cuda-curand-dev-9-0 9.0.176-1 [57.9 MB]\n",
            "Get:18 file:/var/cuda-repo-9-0-local  cuda-cusparse-9-0 9.0.176-1 [25.2 MB]\n",
            "Get:19 file:/var/cuda-repo-9-0-local  cuda-cusparse-dev-9-0 9.0.176-1 [25.3 MB]\n",
            "Get:20 file:/var/cuda-repo-9-0-local  cuda-npp-9-0 9.0.176-1 [46.6 MB]\n",
            "Get:21 file:/var/cuda-repo-9-0-local  cuda-npp-dev-9-0 9.0.176-1 [46.6 MB]\n",
            "Get:22 file:/var/cuda-repo-9-0-local  cuda-nvgraph-9-0 9.0.176-1 [6,081 kB]\n",
            "Get:23 file:/var/cuda-repo-9-0-local  cuda-nvgraph-dev-9-0 9.0.176-1 [5,658 kB]\n",
            "Get:24 file:/var/cuda-repo-9-0-local  cuda-samples-9-0 9.0.176-1 [75.9 MB]\n",
            "Get:25 file:/var/cuda-repo-9-0-local  cuda-documentation-9-0 9.0.176-1 [53.1 MB]\n",
            "Get:26 file:/var/cuda-repo-9-0-local  cuda-libraries-dev-9-0 9.0.176-1 [2,596 B]\n",
            "Get:27 file:/var/cuda-repo-9-0-local  cuda-nvml-dev-9-0 9.0.176-1 [47.6 kB]\n",
            "Get:28 file:/var/cuda-repo-9-0-local  cuda-visual-tools-9-0 9.0.176-1 [398 MB]\n",
            "Get:29 file:/var/cuda-repo-9-0-local  cuda-toolkit-9-0 9.0.176-1 [2,836 B]\n",
            "Get:30 file:/var/cuda-repo-9-0-local  cuda-libraries-9-0 9.0.176-1 [2,566 B]\n",
            "Get:31 file:/var/cuda-repo-9-0-local  cuda-runtime-9-0 9.0.176-1 [2,526 B]\n",
            "Get:32 file:/var/cuda-repo-9-0-local  cuda-demo-suite-9-0 9.0.176-1 [3,880 kB]\n",
            "Get:33 file:/var/cuda-repo-9-0-local  cuda-9-0 9.0.176-1 [2,552 B]\n",
            "Get:34 file:/var/cuda-repo-9-0-local  cuda 9.0.176-1 [2,504 B]\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package cuda-license-9-0.\n",
            "(Reading database ... 144852 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-license-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-license-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-misc-headers-9-0.\n",
            "Preparing to unpack .../01-cuda-misc-headers-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-misc-headers-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-core-9-0.\n",
            "Preparing to unpack .../02-cuda-core-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-core-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cudart-9-0.\n",
            "Preparing to unpack .../03-cuda-cudart-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-9-0.\n",
            "Preparing to unpack .../04-cuda-driver-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-9-0.\n",
            "Preparing to unpack .../05-cuda-cudart-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-9-0.\n",
            "Preparing to unpack .../06-cuda-command-line-tools-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-9-0.\n",
            "Preparing to unpack .../07-cuda-nvrtc-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-9-0.\n",
            "Preparing to unpack .../08-cuda-nvrtc-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-9-0.\n",
            "Preparing to unpack .../09-cuda-cusolver-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-9-0.\n",
            "Preparing to unpack .../10-cuda-cusolver-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cublas-9-0.\n",
            "Preparing to unpack .../11-cuda-cublas-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cublas-dev-9-0.\n",
            "Preparing to unpack .../12-cuda-cublas-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cufft-9-0.\n",
            "Preparing to unpack .../13-cuda-cufft-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-9-0.\n",
            "Preparing to unpack .../14-cuda-cufft-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-curand-9-0.\n",
            "Preparing to unpack .../15-cuda-curand-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-curand-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-9-0.\n",
            "Preparing to unpack .../16-cuda-curand-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-9-0.\n",
            "Preparing to unpack .../17-cuda-cusparse-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-9-0.\n",
            "Preparing to unpack .../18-cuda-cusparse-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-npp-9-0.\n",
            "Preparing to unpack .../19-cuda-npp-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-npp-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-9-0.\n",
            "Preparing to unpack .../20-cuda-npp-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-9-0.\n",
            "Preparing to unpack .../21-cuda-nvgraph-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-9-0.\n",
            "Preparing to unpack .../22-cuda-nvgraph-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-samples-9-0.\n",
            "Preparing to unpack .../23-cuda-samples-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-samples-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-documentation-9-0.\n",
            "Preparing to unpack .../24-cuda-documentation-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-9-0.\n",
            "Preparing to unpack .../25-cuda-libraries-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-9-0.\n",
            "Preparing to unpack .../26-cuda-nvml-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-9-0.\n",
            "Preparing to unpack .../27-cuda-visual-tools-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-9-0.\n",
            "Preparing to unpack .../28-cuda-toolkit-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-libraries-9-0.\n",
            "Preparing to unpack .../29-cuda-libraries-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-runtime-9-0.\n",
            "Preparing to unpack .../30-cuda-runtime-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-runtime-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-demo-suite-9-0.\n",
            "Preparing to unpack .../31-cuda-demo-suite-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-demo-suite-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-9-0.\n",
            "Preparing to unpack .../32-cuda-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda.\n",
            "Preparing to unpack .../33-cuda_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda (9.0.176-1) ...\n",
            "Setting up cuda-license-9-0 (9.0.176-1) ...\n",
            "*** LICENSE AGREEMENT ***\n",
            "By using this software you agree to fully comply with the terms and \n",
            "conditions of the EULA (End User License Agreement). The EULA is located\n",
            "at /usr/local/cuda-9.0/doc/EULA.txt. The EULA can also be found at\n",
            "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
            "terms and conditions of the EULA, do not use the software.\n",
            "\n",
            "Setting up cuda-cusparse-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cudart-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvrtc-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cufft-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusolver-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvml-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-npp-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-misc-headers-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cublas-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-driver-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-curand-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvgraph-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-core-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-libraries-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-runtime-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-npp-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-curand-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-demo-suite-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-visual-tools-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-samples-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-documentation-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-toolkit-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-9-0 (9.0.176-1) ...\n",
            "Setting up cuda (9.0.176-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCLiBujySuT-",
        "outputId": "885357a0-79ba-49c0-b941-2a04a74c422f"
      },
      "source": [
        "%cd deconstructing-lottery-tickets/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deconstructing-lottery-tickets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PflvPBiSiN_",
        "outputId": "e937e1d5-fac6-4d45-ec86-b584425693e2"
      },
      "source": [
        "!python -m pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\r\u001b[K     |█                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 22.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 25.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 27.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 19.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 18.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 18.9MB/s \n",
            "\u001b[?25hCollecting orderedset==2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/38/22cd720cd990b3154f5792e93965606f61b795c7da5901c7e79468b119e7/orderedset-2.0.1.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 15.2MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.11.0)\n",
            "Collecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 215kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (2.10.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (0.10.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (0.35.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (1.33.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15->-r requirements.txt (line 3)) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->-r requirements.txt (line 4)) (0.1.5)\n",
            "Requirement already satisfied: cloudpickle==1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15->-r requirements.txt (line 3)) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 3)) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15->-r requirements.txt (line 3)) (3.4.0)\n",
            "Building wheels for collected packages: orderedset, gast\n",
            "  Building wheel for orderedset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for orderedset: filename=orderedset-2.0.1-cp36-cp36m-linux_x86_64.whl size=245647 sha256=4beeb8b83f6ffc705f1d974c28e0298ad8de5bd17ef752108ede1fdb655453b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/1a/0a/084d78f38459b3111414732e471b0cfbdf05b1931550f60ada\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=d1038e1875d154af8dc05623091b0940e0335c974d29fbc3390691dbb928e7b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built orderedset gast\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, Keras, orderedset, tensorboard, gast, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "Successfully installed Keras-2.2.4 gast-0.2.2 keras-applications-1.0.8 numpy-1.16.4 orderedset-2.0.1 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRWUeyZxSkU9",
        "outputId": "1953375a-f457-4c28-dc12-c3f5a5f70c35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deconstructing-lottery-tickets/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-lDwSoXTpXw",
        "outputId": "de60d7cf-25b8-4713-f731-99d5df0ed473"
      },
      "source": [
        "!python download_mnist.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu18p7i5UBkH",
        "outputId": "67dbae4b-8027-45c0-fde4-e25c00db9042"
      },
      "source": [
        "!python download_cifar10.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idLi0grmSmri",
        "outputId": "170ff703-db72-4def-ff95-ea4e2c9ce204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deconstructing-lottery-tickets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkCuqXViZT6_",
        "outputId": "75ca73eb-88fb-4781-df8a-847366c6c542"
      },
      "source": [
        "!git clone https://github.com/yosinski/GitResultsManager.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GitResultsManager'...\n",
            "remote: Enumerating objects: 293, done.\u001b[K\n",
            "remote: Total 293 (delta 0), reused 0 (delta 0), pack-reused 293\u001b[K\n",
            "Receiving objects: 100% (293/293), 71.57 KiB | 8.95 MiB/s, done.\n",
            "Resolving deltas: 100% (163/163), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq9pM3xzZyT4",
        "outputId": "ffd4ca18-05d0-4922-e070-bd6ee756ba45"
      },
      "source": [
        "!cd GitResultsManager && python setup.py install && cd bin && cp resman resman-td git-recreate /usr/local/bin/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/GitResultsManager\n",
            "copying GitResultsManager/GitResultsManager.py -> build/lib/GitResultsManager\n",
            "copying GitResultsManager/__init__.py -> build/lib/GitResultsManager\n",
            "running build_scripts\n",
            "creating build/scripts-3.6\n",
            "copying bin/git-recreate -> build/scripts-3.6\n",
            "copying bin/rmtd -> build/scripts-3.6\n",
            "copying and adjusting bin/resman -> build/scripts-3.6\n",
            "copying and adjusting bin/resman-td -> build/scripts-3.6\n",
            "changing mode of build/scripts-3.6/resman from 644 to 755\n",
            "changing mode of build/scripts-3.6/resman-td from 644 to 755\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/dist-packages/GitResultsManager\n",
            "copying build/lib/GitResultsManager/GitResultsManager.py -> /usr/local/lib/python3.6/dist-packages/GitResultsManager\n",
            "copying build/lib/GitResultsManager/__init__.py -> /usr/local/lib/python3.6/dist-packages/GitResultsManager\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/GitResultsManager/GitResultsManager.py to GitResultsManager.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/GitResultsManager/__init__.py to __init__.cpython-36.pyc\n",
            "running install_scripts\n",
            "copying build/scripts-3.6/git-recreate -> /usr/local/bin\n",
            "copying build/scripts-3.6/resman -> /usr/local/bin\n",
            "copying build/scripts-3.6/resman-td -> /usr/local/bin\n",
            "copying build/scripts-3.6/rmtd -> /usr/local/bin\n",
            "changing mode of /usr/local/bin/git-recreate to 755\n",
            "changing mode of /usr/local/bin/resman to 755\n",
            "changing mode of /usr/local/bin/resman-td to 755\n",
            "changing mode of /usr/local/bin/rmtd to 755\n",
            "running install_egg_info\n",
            "Writing /usr/local/lib/python3.6/dist-packages/GitResultsManager-0.4.1.egg-info\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM-pBypWZ5GH"
      },
      "source": [
        "!mkdir results"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOTveBa1Y2AA",
        "outputId": "4340778a-c96d-45b5-9472-e24e76df2fca"
      },
      "source": [
        "!bash ./print_train_command.sh iter fc test 0 t"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Logging directory: ./results/iter_lot_fc_orig/test_seed_0\n",
            " Raw entire command: /usr/local/bin/resman -d ./results/iter_lot_fc_orig/ -r test_seed_0 -t {runname} -- python train.py --train_h5 ./data/mnist_train.h5 --test_h5 ./data/mnist_test.h5 --val_h5 ./data/mnist_val.h5 --train_batch_size 60 --num_epochs 55 --eval_every 100 --print_every 100 --save_weights --save_loss --arch fc_lot --seed 0 --opt adam --lr 0.0012 --mode save_all --large_batch_size 5000 --test_batch_size 0 --val_batch_size 0\n",
            "           Hostname: 6a1d339ab7b8\n",
            "  Working directory: /content/deconstructing-lottery-tickets\n",
            " Raw script command: python train.py --train_h5 ./data/mnist_train.h5 --test_h5 ./data/mnist_test.h5 --val_h5 ./data/mnist_val.h5 --train_batch_size 60 --num_epochs 55 --eval_every 100 --print_every 100 --save_weights --save_loss --arch fc_lot --seed 0 --opt adam --lr 0.0012 --mode save_all --large_batch_size 5000 --test_batch_size 0 --val_batch_size 0\n",
            "     Script command: python train.py --train_h5 ./data/mnist_train.h5 --test_h5 ./data/mnist_test.h5 --val_h5 ./data/mnist_val.h5 --train_batch_size 60 --num_epochs 55 --eval_every 100 --print_every 100 --save_weights --save_loss --arch fc_lot --seed 0 --opt adam --lr 0.0012 --mode save_all --large_batch_size 5000 --test_batch_size 0 --val_batch_size 0\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/__init__.py:22: The name tf.layers.Conv2D is deprecated. Please use tf.compat.v1.layers.Conv2D instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/__init__.py:23: The name tf.layers.MaxPooling2D is deprecated. Please use tf.compat.v1.layers.MaxPooling2D instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/__init__.py:24: The name tf.layers.Flatten is deprecated. Please use tf.compat.v1.layers.Flatten instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/__init__.py:25: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/__init__.py:26: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/__init__.py:33: The name tf.layers.Dropout is deprecated. Please use tf.compat.v1.layers.Dropout instead.\n",
            "\n",
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From train.py:312: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:75: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:91: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/tfutil.py:669: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/tfutil.py:359: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/tfutil.py:388: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:98: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:362: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n",
            "2020-12-01 03:33:30.879590: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-12-01 03:33:30.883782: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-12-01 03:33:30.883993: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28ff800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-01 03:33:30.884016: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-12-01 03:33:30.887487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-01 03:33:31.065329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-01 03:33:31.066223: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28ff9c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-01 03:33:31.066256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-12-01 03:33:31.067375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-01 03:33:31.068050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-01 03:33:31.069685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-01 03:33:31.284867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-12-01 03:33:31.374703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-12-01 03:33:31.388174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-12-01 03:33:31.635032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-12-01 03:33:31.787070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-12-01 03:33:32.249549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-01 03:33:32.249869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-01 03:33:32.250678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-01 03:33:32.251276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-12-01 03:33:32.251387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-12-01 03:33:32.252772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-01 03:33:32.252807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-12-01 03:33:32.252821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-12-01 03:33:32.253055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-01 03:33:32.253785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-01 03:33:32.254380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From train.py:363: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:372: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:173: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:173: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/deconstructing-lottery-tickets/tf_plus/backend.py:27: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "2020-12-01 03:33:33.019728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "WARNING:tensorflow:From train.py:150: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Normalizing images by a factor of 255\n",
            "Data shapes: (55000, 28, 28, 1) (55000,) (10000, 28, 28, 1) (10000,)\n",
            "WARNING batch size doesn't divide train set evenly\n",
            "All model weights:\n",
            "                                                NAME:       SIZE SHAPE               \n",
            "                    sequential_network/fc_1/kernel:0:     235200 [784, 300]          \n",
            "                      sequential_network/fc_1/bias:0:        300 [300]               \n",
            "                    sequential_network/fc_2/kernel:0:      30000 [300, 100]          \n",
            "                      sequential_network/fc_2/bias:0:        100 [100]               \n",
            "                    sequential_network/fc_3/kernel:0:       1000 [100, 10]           \n",
            "                      sequential_network/fc_3/bias:0:         10 [10]                \n",
            "                                               Total:     266610\n",
            "[10, 20, 50, -1]\n",
            "0: train acc = 0.0552, val acc = 0.0534, test acc = 0.0567, train loss = 2.3478, val loss = 2.3546, test loss = 2.3451 (1.57 s)\n",
            "100: train acc = 0.9128, val acc = 0.9156, test acc = 0.9153, train loss = 0.3079, val loss = 0.2906, test loss = 0.2989 (2.42 s)\n",
            "200: train acc = 0.9314, val acc = 0.9316, test acc = 0.9316, train loss = 0.2379, val loss = 0.2275, test loss = 0.2336 (3.13 s)\n",
            "300: train acc = 0.9503, val acc = 0.9502, test acc = 0.9479, train loss = 0.1774, val loss = 0.1743, test loss = 0.1816 (3.62 s)\n",
            "400: train acc = 0.9522, val acc = 0.9514, test acc = 0.9478, train loss = 0.1596, val loss = 0.1624, test loss = 0.1667 (4.17 s)\n",
            "500: train acc = 0.9582, val acc = 0.9546, test acc = 0.9532, train loss = 0.1426, val loss = 0.1463, test loss = 0.1500 (4.81 s)\n",
            "600: train acc = 0.9614, val acc = 0.9572, test acc = 0.9593, train loss = 0.1291, val loss = 0.1373, test loss = 0.1326 (5.53 s)\n",
            "700: train acc = 0.9641, val acc = 0.9608, test acc = 0.9580, train loss = 0.1216, val loss = 0.1262, test loss = 0.1382 (6.03 s)\n",
            "800: train acc = 0.9663, val acc = 0.9632, test acc = 0.9583, train loss = 0.1145, val loss = 0.1276, test loss = 0.1324 (6.59 s)\n",
            "900: train acc = 0.9686, val acc = 0.9564, test acc = 0.9620, train loss = 0.1026, val loss = 0.1277, test loss = 0.1176 (7.21 s)\n",
            "1000: train acc = 0.9741, val acc = 0.9678, test acc = 0.9678, train loss = 0.0856, val loss = 0.1019, test loss = 0.1025 (7.92 s)\n",
            "1100: train acc = 0.9758, val acc = 0.9660, test acc = 0.9645, train loss = 0.0825, val loss = 0.0982, test loss = 0.1062 (8.41 s)\n",
            "1200: train acc = 0.9780, val acc = 0.9682, test acc = 0.9688, train loss = 0.0721, val loss = 0.0966, test loss = 0.0982 (8.96 s)\n",
            "1300: train acc = 0.9779, val acc = 0.9706, test acc = 0.9686, train loss = 0.0735, val loss = 0.0932, test loss = 0.1018 (9.59 s)\n",
            "1400: train acc = 0.9802, val acc = 0.9686, test acc = 0.9709, train loss = 0.0685, val loss = 0.0933, test loss = 0.0916 (10.29 s)\n",
            "1500: train acc = 0.9770, val acc = 0.9668, test acc = 0.9663, train loss = 0.0744, val loss = 0.1047, test loss = 0.1087 (10.77 s)\n",
            "1600: train acc = 0.9806, val acc = 0.9726, test acc = 0.9715, train loss = 0.0638, val loss = 0.0900, test loss = 0.0884 (11.31 s)\n",
            "1700: train acc = 0.9811, val acc = 0.9738, test acc = 0.9710, train loss = 0.0605, val loss = 0.0845, test loss = 0.0871 (11.93 s)\n",
            "1800: train acc = 0.9780, val acc = 0.9702, test acc = 0.9680, train loss = 0.0707, val loss = 0.0951, test loss = 0.1030 (12.63 s)\n",
            "1900: train acc = 0.9868, val acc = 0.9748, test acc = 0.9751, train loss = 0.0447, val loss = 0.0742, test loss = 0.0773 (13.12 s)\n",
            "2000: train acc = 0.9860, val acc = 0.9752, test acc = 0.9735, train loss = 0.0470, val loss = 0.0777, test loss = 0.0811 (13.70 s)\n",
            "2100: train acc = 0.9845, val acc = 0.9742, test acc = 0.9719, train loss = 0.0495, val loss = 0.0788, test loss = 0.0821 (14.33 s)\n",
            "2200: train acc = 0.9859, val acc = 0.9766, test acc = 0.9749, train loss = 0.0480, val loss = 0.0724, test loss = 0.0794 (15.04 s)\n",
            "2300: train acc = 0.9845, val acc = 0.9740, test acc = 0.9745, train loss = 0.0497, val loss = 0.0769, test loss = 0.0805 (15.56 s)\n",
            "2400: train acc = 0.9825, val acc = 0.9714, test acc = 0.9712, train loss = 0.0561, val loss = 0.0930, test loss = 0.0937 (16.15 s)\n",
            "2500: train acc = 0.9890, val acc = 0.9790, test acc = 0.9770, train loss = 0.0366, val loss = 0.0691, test loss = 0.0700 (16.78 s)\n",
            "2600: train acc = 0.9867, val acc = 0.9784, test acc = 0.9748, train loss = 0.0424, val loss = 0.0762, test loss = 0.0819 (17.48 s)\n",
            "2700: train acc = 0.9875, val acc = 0.9754, test acc = 0.9773, train loss = 0.0406, val loss = 0.0786, test loss = 0.0724 (17.96 s)\n",
            "2800: train acc = 0.9894, val acc = 0.9790, test acc = 0.9768, train loss = 0.0358, val loss = 0.0699, test loss = 0.0743 (18.51 s)\n",
            "2900: train acc = 0.9895, val acc = 0.9788, test acc = 0.9748, train loss = 0.0339, val loss = 0.0718, test loss = 0.0746 (19.16 s)\n",
            "3000: train acc = 0.9890, val acc = 0.9796, test acc = 0.9761, train loss = 0.0353, val loss = 0.0654, test loss = 0.0792 (19.86 s)\n",
            "3100: train acc = 0.9906, val acc = 0.9812, test acc = 0.9784, train loss = 0.0297, val loss = 0.0691, test loss = 0.0695 (20.35 s)\n",
            "3200: train acc = 0.9905, val acc = 0.9772, test acc = 0.9775, train loss = 0.0323, val loss = 0.0713, test loss = 0.0714 (20.91 s)\n",
            "3300: train acc = 0.9909, val acc = 0.9804, test acc = 0.9769, train loss = 0.0289, val loss = 0.0692, test loss = 0.0725 (21.53 s)\n",
            "3400: train acc = 0.9866, val acc = 0.9738, test acc = 0.9753, train loss = 0.0398, val loss = 0.0881, test loss = 0.0826 (22.24 s)\n",
            "3500: train acc = 0.9904, val acc = 0.9780, test acc = 0.9768, train loss = 0.0299, val loss = 0.0777, test loss = 0.0756 (22.72 s)\n",
            "3600: train acc = 0.9926, val acc = 0.9810, test acc = 0.9776, train loss = 0.0250, val loss = 0.0638, test loss = 0.0663 (23.26 s)\n",
            "3700: train acc = 0.9917, val acc = 0.9790, test acc = 0.9777, train loss = 0.0270, val loss = 0.0742, test loss = 0.0732 (23.89 s)\n",
            "3800: train acc = 0.9915, val acc = 0.9784, test acc = 0.9777, train loss = 0.0255, val loss = 0.0741, test loss = 0.0729 (24.60 s)\n",
            "3900: train acc = 0.9898, val acc = 0.9802, test acc = 0.9733, train loss = 0.0320, val loss = 0.0723, test loss = 0.0831 (25.10 s)\n",
            "4000: train acc = 0.9889, val acc = 0.9772, test acc = 0.9716, train loss = 0.0333, val loss = 0.0783, test loss = 0.0870 (25.65 s)\n",
            "4100: train acc = 0.9887, val acc = 0.9762, test acc = 0.9752, train loss = 0.0338, val loss = 0.0888, test loss = 0.0858 (26.29 s)\n",
            "4200: train acc = 0.9900, val acc = 0.9754, test acc = 0.9740, train loss = 0.0299, val loss = 0.0853, test loss = 0.0854 (26.99 s)\n",
            "4300: train acc = 0.9914, val acc = 0.9766, test acc = 0.9778, train loss = 0.0272, val loss = 0.0783, test loss = 0.0743 (27.48 s)\n",
            "4400: train acc = 0.9933, val acc = 0.9808, test acc = 0.9779, train loss = 0.0220, val loss = 0.0659, test loss = 0.0709 (28.03 s)\n",
            "4500: train acc = 0.9927, val acc = 0.9782, test acc = 0.9781, train loss = 0.0224, val loss = 0.0675, test loss = 0.0734 (28.65 s)\n",
            "4600: train acc = 0.9938, val acc = 0.9826, test acc = 0.9796, train loss = 0.0201, val loss = 0.0614, test loss = 0.0712 (29.37 s)\n",
            "4700: train acc = 0.9959, val acc = 0.9828, test acc = 0.9798, train loss = 0.0146, val loss = 0.0601, test loss = 0.0692 (29.88 s)\n",
            "4800: train acc = 0.9895, val acc = 0.9734, test acc = 0.9724, train loss = 0.0317, val loss = 0.0905, test loss = 0.0957 (30.43 s)\n",
            "4900: train acc = 0.9910, val acc = 0.9792, test acc = 0.9750, train loss = 0.0274, val loss = 0.0694, test loss = 0.0875 (31.12 s)\n",
            "5000: train acc = 0.9920, val acc = 0.9792, test acc = 0.9766, train loss = 0.0238, val loss = 0.0768, test loss = 0.0850 (31.83 s)\n",
            "5100: train acc = 0.9925, val acc = 0.9774, test acc = 0.9758, train loss = 0.0222, val loss = 0.0766, test loss = 0.0838 (32.32 s)\n",
            "5200: train acc = 0.9922, val acc = 0.9778, test acc = 0.9759, train loss = 0.0238, val loss = 0.0736, test loss = 0.0833 (32.86 s)\n",
            "5300: train acc = 0.9926, val acc = 0.9770, test acc = 0.9771, train loss = 0.0232, val loss = 0.0814, test loss = 0.0780 (33.48 s)\n",
            "5400: train acc = 0.9930, val acc = 0.9764, test acc = 0.9769, train loss = 0.0215, val loss = 0.0786, test loss = 0.0756 (34.18 s)\n",
            "5500: train acc = 0.9930, val acc = 0.9786, test acc = 0.9795, train loss = 0.0204, val loss = 0.0807, test loss = 0.0760 (34.67 s)\n",
            "5600: train acc = 0.9953, val acc = 0.9810, test acc = 0.9803, train loss = 0.0141, val loss = 0.0734, test loss = 0.0703 (35.23 s)\n",
            "5700: train acc = 0.9960, val acc = 0.9836, test acc = 0.9801, train loss = 0.0122, val loss = 0.0621, test loss = 0.0678 (35.85 s)\n",
            "5800: train acc = 0.9952, val acc = 0.9806, test acc = 0.9786, train loss = 0.0146, val loss = 0.0765, test loss = 0.0775 (36.55 s)\n",
            "5900: train acc = 0.9925, val acc = 0.9784, test acc = 0.9738, train loss = 0.0239, val loss = 0.0830, test loss = 0.0924 (37.05 s)\n",
            "6000: train acc = 0.9955, val acc = 0.9806, test acc = 0.9787, train loss = 0.0149, val loss = 0.0619, test loss = 0.0777 (37.60 s)\n",
            "6100: train acc = 0.9953, val acc = 0.9818, test acc = 0.9787, train loss = 0.0138, val loss = 0.0681, test loss = 0.0812 (38.22 s)\n",
            "6200: train acc = 0.9919, val acc = 0.9760, test acc = 0.9778, train loss = 0.0241, val loss = 0.0956, test loss = 0.0872 (38.92 s)\n",
            "6300: train acc = 0.9935, val acc = 0.9780, test acc = 0.9777, train loss = 0.0198, val loss = 0.0862, test loss = 0.0834 (39.42 s)\n",
            "6400: train acc = 0.9938, val acc = 0.9782, test acc = 0.9757, train loss = 0.0185, val loss = 0.0858, test loss = 0.0799 (39.97 s)\n",
            "6500: train acc = 0.9967, val acc = 0.9818, test acc = 0.9813, train loss = 0.0103, val loss = 0.0677, test loss = 0.0723 (40.59 s)\n",
            "6600: train acc = 0.9966, val acc = 0.9826, test acc = 0.9811, train loss = 0.0117, val loss = 0.0665, test loss = 0.0760 (41.32 s)\n",
            "6700: train acc = 0.9917, val acc = 0.9768, test acc = 0.9761, train loss = 0.0245, val loss = 0.0913, test loss = 0.0975 (41.80 s)\n",
            "6800: train acc = 0.9958, val acc = 0.9782, test acc = 0.9802, train loss = 0.0129, val loss = 0.0775, test loss = 0.0772 (42.35 s)\n",
            "6900: train acc = 0.9926, val acc = 0.9804, test acc = 0.9783, train loss = 0.0212, val loss = 0.0835, test loss = 0.0962 (42.98 s)\n",
            "7000: train acc = 0.9888, val acc = 0.9730, test acc = 0.9726, train loss = 0.0348, val loss = 0.1004, test loss = 0.1117 (43.68 s)\n",
            "7100: train acc = 0.9947, val acc = 0.9804, test acc = 0.9785, train loss = 0.0158, val loss = 0.0733, test loss = 0.0858 (44.17 s)\n",
            "7200: train acc = 0.9942, val acc = 0.9798, test acc = 0.9796, train loss = 0.0163, val loss = 0.0763, test loss = 0.0816 (44.72 s)\n",
            "7300: train acc = 0.9953, val acc = 0.9788, test acc = 0.9786, train loss = 0.0140, val loss = 0.0792, test loss = 0.0883 (45.34 s)\n",
            "7400: train acc = 0.9958, val acc = 0.9790, test acc = 0.9790, train loss = 0.0135, val loss = 0.0826, test loss = 0.0815 (46.05 s)\n",
            "7500: train acc = 0.9970, val acc = 0.9812, test acc = 0.9807, train loss = 0.0092, val loss = 0.0733, test loss = 0.0785 (46.55 s)\n",
            "7600: train acc = 0.9952, val acc = 0.9814, test acc = 0.9798, train loss = 0.0141, val loss = 0.0784, test loss = 0.0849 (47.12 s)\n",
            "7700: train acc = 0.9952, val acc = 0.9804, test acc = 0.9794, train loss = 0.0145, val loss = 0.0788, test loss = 0.0850 (47.74 s)\n",
            "7800: train acc = 0.9964, val acc = 0.9812, test acc = 0.9813, train loss = 0.0112, val loss = 0.0795, test loss = 0.0745 (48.45 s)\n",
            "7900: train acc = 0.9972, val acc = 0.9824, test acc = 0.9807, train loss = 0.0092, val loss = 0.0731, test loss = 0.0743 (48.93 s)\n",
            "8000: train acc = 0.9960, val acc = 0.9808, test acc = 0.9812, train loss = 0.0124, val loss = 0.0824, test loss = 0.0813 (49.49 s)\n",
            "8100: train acc = 0.9853, val acc = 0.9680, test acc = 0.9667, train loss = 0.0479, val loss = 0.1314, test loss = 0.1531 (50.12 s)\n",
            "8200: train acc = 0.9946, val acc = 0.9790, test acc = 0.9781, train loss = 0.0143, val loss = 0.0852, test loss = 0.0916 (50.82 s)\n",
            "8300: train acc = 0.9963, val acc = 0.9816, test acc = 0.9787, train loss = 0.0106, val loss = 0.0775, test loss = 0.0853 (51.31 s)\n",
            "8400: train acc = 0.9969, val acc = 0.9824, test acc = 0.9793, train loss = 0.0096, val loss = 0.0742, test loss = 0.0825 (51.85 s)\n",
            "8500: train acc = 0.9977, val acc = 0.9838, test acc = 0.9810, train loss = 0.0068, val loss = 0.0727, test loss = 0.0840 (52.48 s)\n",
            "8600: train acc = 0.9935, val acc = 0.9780, test acc = 0.9754, train loss = 0.0193, val loss = 0.0969, test loss = 0.1074 (53.18 s)\n",
            "8700: train acc = 0.9960, val acc = 0.9774, test acc = 0.9782, train loss = 0.0116, val loss = 0.0879, test loss = 0.0929 (53.67 s)\n",
            "8800: train acc = 0.9971, val acc = 0.9802, test acc = 0.9789, train loss = 0.0092, val loss = 0.0858, test loss = 0.0921 (54.22 s)\n",
            "8900: train acc = 0.9965, val acc = 0.9798, test acc = 0.9773, train loss = 0.0105, val loss = 0.0819, test loss = 0.0942 (54.84 s)\n",
            "9000: train acc = 0.9951, val acc = 0.9794, test acc = 0.9785, train loss = 0.0141, val loss = 0.0898, test loss = 0.0921 (55.54 s)\n",
            "9100: train acc = 0.9956, val acc = 0.9806, test acc = 0.9769, train loss = 0.0132, val loss = 0.0855, test loss = 0.0972 (56.03 s)\n",
            "9200: train acc = 0.9961, val acc = 0.9828, test acc = 0.9801, train loss = 0.0114, val loss = 0.0818, test loss = 0.0905 (56.60 s)\n",
            "9300: train acc = 0.9959, val acc = 0.9806, test acc = 0.9784, train loss = 0.0125, val loss = 0.0909, test loss = 0.0948 (57.24 s)\n",
            "9400: train acc = 0.9974, val acc = 0.9812, test acc = 0.9811, train loss = 0.0082, val loss = 0.0789, test loss = 0.0883 (57.98 s)\n",
            "9500: train acc = 0.9976, val acc = 0.9832, test acc = 0.9817, train loss = 0.0074, val loss = 0.0685, test loss = 0.0792 (58.48 s)\n",
            "9600: train acc = 0.9962, val acc = 0.9808, test acc = 0.9787, train loss = 0.0108, val loss = 0.0772, test loss = 0.0906 (59.02 s)\n",
            "9700: train acc = 0.9960, val acc = 0.9782, test acc = 0.9784, train loss = 0.0117, val loss = 0.0790, test loss = 0.0949 (59.68 s)\n",
            "9800: train acc = 0.9965, val acc = 0.9814, test acc = 0.9783, train loss = 0.0113, val loss = 0.0813, test loss = 0.0927 (60.40 s)\n",
            "9900: train acc = 0.9959, val acc = 0.9788, test acc = 0.9790, train loss = 0.0120, val loss = 0.0794, test loss = 0.0997 (60.92 s)\n",
            "10000: train acc = 0.9960, val acc = 0.9792, test acc = 0.9763, train loss = 0.0126, val loss = 0.0882, test loss = 0.1054 (61.48 s)\n",
            "10100: train acc = 0.9970, val acc = 0.9784, test acc = 0.9777, train loss = 0.0096, val loss = 0.0882, test loss = 0.1049 (62.12 s)\n",
            "10200: train acc = 0.9938, val acc = 0.9750, test acc = 0.9762, train loss = 0.0208, val loss = 0.1115, test loss = 0.1138 (62.83 s)\n",
            "10300: train acc = 0.9960, val acc = 0.9796, test acc = 0.9778, train loss = 0.0112, val loss = 0.0862, test loss = 0.1035 (63.32 s)\n",
            "10400: train acc = 0.9955, val acc = 0.9796, test acc = 0.9789, train loss = 0.0120, val loss = 0.0927, test loss = 0.0944 (63.87 s)\n",
            "10500: train acc = 0.9967, val acc = 0.9796, test acc = 0.9802, train loss = 0.0101, val loss = 0.0960, test loss = 0.0884 (64.52 s)\n",
            "10600: train acc = 0.9982, val acc = 0.9832, test acc = 0.9807, train loss = 0.0058, val loss = 0.0820, test loss = 0.0845 (65.22 s)\n",
            "10700: train acc = 0.9983, val acc = 0.9816, test acc = 0.9817, train loss = 0.0052, val loss = 0.0867, test loss = 0.0854 (65.70 s)\n",
            "10800: train acc = 0.9985, val acc = 0.9832, test acc = 0.9822, train loss = 0.0049, val loss = 0.0795, test loss = 0.0819 (66.26 s)\n",
            "10900: train acc = 0.9959, val acc = 0.9808, test acc = 0.9776, train loss = 0.0111, val loss = 0.0928, test loss = 0.1113 (66.89 s)\n",
            "11000: train acc = 0.9973, val acc = 0.9826, test acc = 0.9801, train loss = 0.0082, val loss = 0.0884, test loss = 0.1029 (67.60 s)\n",
            "11100: train acc = 0.9972, val acc = 0.9810, test acc = 0.9802, train loss = 0.0088, val loss = 0.0928, test loss = 0.1002 (68.09 s)\n",
            "11200: train acc = 0.9939, val acc = 0.9772, test acc = 0.9767, train loss = 0.0181, val loss = 0.1118, test loss = 0.1148 (68.64 s)\n",
            "11300: train acc = 0.9961, val acc = 0.9766, test acc = 0.9777, train loss = 0.0113, val loss = 0.0999, test loss = 0.1013 (69.25 s)\n",
            "11400: train acc = 0.9962, val acc = 0.9798, test acc = 0.9803, train loss = 0.0122, val loss = 0.0951, test loss = 0.1032 (69.96 s)\n",
            "11500: train acc = 0.9915, val acc = 0.9740, test acc = 0.9749, train loss = 0.0303, val loss = 0.1109, test loss = 0.1226 (70.44 s)\n",
            "11600: train acc = 0.9963, val acc = 0.9820, test acc = 0.9787, train loss = 0.0109, val loss = 0.0874, test loss = 0.1011 (70.99 s)\n",
            "11700: train acc = 0.9969, val acc = 0.9818, test acc = 0.9804, train loss = 0.0087, val loss = 0.0821, test loss = 0.0953 (71.61 s)\n",
            "11800: train acc = 0.9937, val acc = 0.9774, test acc = 0.9766, train loss = 0.0175, val loss = 0.1001, test loss = 0.1120 (72.33 s)\n",
            "11900: train acc = 0.9957, val acc = 0.9810, test acc = 0.9782, train loss = 0.0124, val loss = 0.0966, test loss = 0.1037 (72.82 s)\n",
            "12000: train acc = 0.9984, val acc = 0.9816, test acc = 0.9817, train loss = 0.0049, val loss = 0.0840, test loss = 0.0884 (73.37 s)\n",
            "12100: train acc = 0.9987, val acc = 0.9844, test acc = 0.9816, train loss = 0.0039, val loss = 0.0802, test loss = 0.0917 (74.00 s)\n",
            "12200: train acc = 0.9972, val acc = 0.9822, test acc = 0.9786, train loss = 0.0091, val loss = 0.0891, test loss = 0.0959 (74.70 s)\n",
            "12300: train acc = 0.9985, val acc = 0.9822, test acc = 0.9803, train loss = 0.0044, val loss = 0.0802, test loss = 0.0936 (75.18 s)\n",
            "12400: train acc = 0.9989, val acc = 0.9854, test acc = 0.9805, train loss = 0.0034, val loss = 0.0712, test loss = 0.0959 (75.75 s)\n",
            "12500: train acc = 0.9975, val acc = 0.9824, test acc = 0.9804, train loss = 0.0069, val loss = 0.0965, test loss = 0.1073 (76.36 s)\n",
            "12600: train acc = 0.9975, val acc = 0.9806, test acc = 0.9804, train loss = 0.0077, val loss = 0.1013, test loss = 0.0999 (77.11 s)\n",
            "12700: train acc = 0.9962, val acc = 0.9782, test acc = 0.9807, train loss = 0.0124, val loss = 0.1042, test loss = 0.0979 (77.62 s)\n",
            "12800: train acc = 0.9952, val acc = 0.9786, test acc = 0.9780, train loss = 0.0138, val loss = 0.1014, test loss = 0.1076 (78.18 s)\n",
            "12900: train acc = 0.9964, val acc = 0.9806, test acc = 0.9784, train loss = 0.0105, val loss = 0.0866, test loss = 0.1017 (78.82 s)\n",
            "13000: train acc = 0.9977, val acc = 0.9816, test acc = 0.9793, train loss = 0.0073, val loss = 0.0873, test loss = 0.1117 (79.52 s)\n",
            "13100: train acc = 0.9956, val acc = 0.9792, test acc = 0.9776, train loss = 0.0141, val loss = 0.1116, test loss = 0.1165 (80.02 s)\n",
            "13200: train acc = 0.9949, val acc = 0.9802, test acc = 0.9783, train loss = 0.0177, val loss = 0.1056, test loss = 0.1156 (80.57 s)\n",
            "13300: train acc = 0.9946, val acc = 0.9780, test acc = 0.9780, train loss = 0.0162, val loss = 0.1175, test loss = 0.1149 (81.20 s)\n",
            "13400: train acc = 0.9973, val acc = 0.9782, test acc = 0.9799, train loss = 0.0083, val loss = 0.0876, test loss = 0.1008 (81.94 s)\n",
            "13500: train acc = 0.9971, val acc = 0.9792, test acc = 0.9803, train loss = 0.0101, val loss = 0.0927, test loss = 0.1104 (82.46 s)\n",
            "13600: train acc = 0.9966, val acc = 0.9818, test acc = 0.9790, train loss = 0.0102, val loss = 0.0871, test loss = 0.1044 (83.00 s)\n",
            "13700: train acc = 0.9981, val acc = 0.9820, test acc = 0.9814, train loss = 0.0061, val loss = 0.0839, test loss = 0.0976 (83.64 s)\n",
            "13800: train acc = 0.9980, val acc = 0.9822, test acc = 0.9799, train loss = 0.0065, val loss = 0.0861, test loss = 0.1110 (84.34 s)\n",
            "13900: train acc = 0.9973, val acc = 0.9798, test acc = 0.9784, train loss = 0.0079, val loss = 0.0956, test loss = 0.1123 (84.83 s)\n",
            "14000: train acc = 0.9983, val acc = 0.9830, test acc = 0.9807, train loss = 0.0046, val loss = 0.0757, test loss = 0.1009 (85.40 s)\n",
            "14100: train acc = 0.9977, val acc = 0.9826, test acc = 0.9798, train loss = 0.0064, val loss = 0.0936, test loss = 0.1050 (86.07 s)\n",
            "14200: train acc = 0.9977, val acc = 0.9808, test acc = 0.9811, train loss = 0.0070, val loss = 0.0929, test loss = 0.0874 (86.80 s)\n",
            "14300: train acc = 0.9990, val acc = 0.9810, test acc = 0.9818, train loss = 0.0030, val loss = 0.0910, test loss = 0.0888 (87.29 s)\n",
            "14400: train acc = 0.9979, val acc = 0.9822, test acc = 0.9815, train loss = 0.0068, val loss = 0.0904, test loss = 0.0939 (87.88 s)\n",
            "14500: train acc = 0.9959, val acc = 0.9824, test acc = 0.9774, train loss = 0.0147, val loss = 0.1033, test loss = 0.1296 (88.50 s)\n",
            "14600: train acc = 0.9957, val acc = 0.9792, test acc = 0.9772, train loss = 0.0134, val loss = 0.1035, test loss = 0.1212 (89.20 s)\n",
            "14700: train acc = 0.9966, val acc = 0.9822, test acc = 0.9778, train loss = 0.0097, val loss = 0.0944, test loss = 0.1174 (89.71 s)\n",
            "14800: train acc = 0.9982, val acc = 0.9830, test acc = 0.9793, train loss = 0.0057, val loss = 0.0922, test loss = 0.1018 (90.27 s)\n",
            "14900: train acc = 0.9987, val acc = 0.9850, test acc = 0.9814, train loss = 0.0045, val loss = 0.0835, test loss = 0.0984 (90.90 s)\n",
            "15000: train acc = 0.9987, val acc = 0.9856, test acc = 0.9810, train loss = 0.0041, val loss = 0.0786, test loss = 0.1023 (91.60 s)\n",
            "15100: train acc = 0.9971, val acc = 0.9812, test acc = 0.9770, train loss = 0.0092, val loss = 0.0963, test loss = 0.1161 (92.08 s)\n",
            "15200: train acc = 0.9968, val acc = 0.9836, test acc = 0.9784, train loss = 0.0111, val loss = 0.0879, test loss = 0.1201 (92.65 s)\n",
            "15300: train acc = 0.9943, val acc = 0.9792, test acc = 0.9760, train loss = 0.0172, val loss = 0.1093, test loss = 0.1235 (93.27 s)\n",
            "15400: train acc = 0.9976, val acc = 0.9832, test acc = 0.9790, train loss = 0.0065, val loss = 0.0798, test loss = 0.1017 (93.99 s)\n",
            "15500: train acc = 0.9981, val acc = 0.9846, test acc = 0.9805, train loss = 0.0055, val loss = 0.0812, test loss = 0.1003 (94.50 s)\n",
            "15600: train acc = 0.9966, val acc = 0.9812, test acc = 0.9814, train loss = 0.0108, val loss = 0.1034, test loss = 0.1003 (95.05 s)\n",
            "15700: train acc = 0.9974, val acc = 0.9844, test acc = 0.9818, train loss = 0.0111, val loss = 0.0932, test loss = 0.1076 (95.70 s)\n",
            "15800: train acc = 0.9975, val acc = 0.9850, test acc = 0.9785, train loss = 0.0081, val loss = 0.0811, test loss = 0.1169 (96.40 s)\n",
            "15900: train acc = 0.9979, val acc = 0.9832, test acc = 0.9809, train loss = 0.0068, val loss = 0.0848, test loss = 0.1048 (96.90 s)\n",
            "16000: train acc = 0.9943, val acc = 0.9774, test acc = 0.9783, train loss = 0.0192, val loss = 0.1037, test loss = 0.1235 (97.45 s)\n",
            "16100: train acc = 0.9966, val acc = 0.9804, test acc = 0.9798, train loss = 0.0093, val loss = 0.0896, test loss = 0.1099 (98.08 s)\n",
            "16200: train acc = 0.9968, val acc = 0.9802, test acc = 0.9784, train loss = 0.0094, val loss = 0.0952, test loss = 0.1127 (98.81 s)\n",
            "16300: train acc = 0.9974, val acc = 0.9848, test acc = 0.9803, train loss = 0.0077, val loss = 0.0885, test loss = 0.1051 (99.28 s)\n",
            "16400: train acc = 0.9981, val acc = 0.9850, test acc = 0.9799, train loss = 0.0052, val loss = 0.0842, test loss = 0.1031 (99.84 s)\n",
            "16500: train acc = 0.9974, val acc = 0.9840, test acc = 0.9797, train loss = 0.0074, val loss = 0.0757, test loss = 0.1052 (100.46 s)\n",
            "16600: train acc = 0.9977, val acc = 0.9826, test acc = 0.9807, train loss = 0.0069, val loss = 0.0853, test loss = 0.1033 (101.16 s)\n",
            "16700: train acc = 0.9989, val acc = 0.9854, test acc = 0.9825, train loss = 0.0033, val loss = 0.0769, test loss = 0.1045 (101.65 s)\n",
            "16800: train acc = 0.9989, val acc = 0.9850, test acc = 0.9826, train loss = 0.0037, val loss = 0.0780, test loss = 0.0981 (102.21 s)\n",
            "16900: train acc = 0.9992, val acc = 0.9858, test acc = 0.9833, train loss = 0.0024, val loss = 0.0714, test loss = 0.1007 (102.86 s)\n",
            "17000: train acc = 0.9963, val acc = 0.9812, test acc = 0.9799, train loss = 0.0114, val loss = 0.1019, test loss = 0.1198 (103.58 s)\n",
            "17100: train acc = 0.9972, val acc = 0.9816, test acc = 0.9805, train loss = 0.0085, val loss = 0.1036, test loss = 0.1133 (104.09 s)\n",
            "17200: train acc = 0.9950, val acc = 0.9772, test acc = 0.9748, train loss = 0.0168, val loss = 0.1084, test loss = 0.1423 (104.66 s)\n",
            "17300: train acc = 0.9974, val acc = 0.9830, test acc = 0.9805, train loss = 0.0087, val loss = 0.0879, test loss = 0.1143 (105.29 s)\n",
            "17400: train acc = 0.9954, val acc = 0.9806, test acc = 0.9784, train loss = 0.0158, val loss = 0.1013, test loss = 0.1315 (106.00 s)\n",
            "17500: train acc = 0.9959, val acc = 0.9800, test acc = 0.9777, train loss = 0.0142, val loss = 0.1092, test loss = 0.1284 (106.49 s)\n",
            "17600: train acc = 0.9981, val acc = 0.9828, test acc = 0.9804, train loss = 0.0062, val loss = 0.0867, test loss = 0.1060 (107.04 s)\n",
            "17700: train acc = 0.9980, val acc = 0.9812, test acc = 0.9800, train loss = 0.0057, val loss = 0.0910, test loss = 0.1181 (107.67 s)\n",
            "17800: train acc = 0.9990, val acc = 0.9838, test acc = 0.9816, train loss = 0.0026, val loss = 0.0854, test loss = 0.1097 (108.41 s)\n",
            "17900: train acc = 0.9987, val acc = 0.9844, test acc = 0.9805, train loss = 0.0035, val loss = 0.0805, test loss = 0.1079 (108.92 s)\n",
            "18000: train acc = 0.9985, val acc = 0.9826, test acc = 0.9815, train loss = 0.0050, val loss = 0.0854, test loss = 0.1030 (109.47 s)\n",
            "18100: train acc = 0.9977, val acc = 0.9804, test acc = 0.9794, train loss = 0.0070, val loss = 0.0909, test loss = 0.1183 (110.09 s)\n",
            "18200: train acc = 0.9984, val acc = 0.9828, test acc = 0.9803, train loss = 0.0043, val loss = 0.0845, test loss = 0.1057 (110.80 s)\n",
            "18300: train acc = 0.9984, val acc = 0.9810, test acc = 0.9808, train loss = 0.0047, val loss = 0.0903, test loss = 0.1151 (111.28 s)\n",
            "18400: train acc = 0.9987, val acc = 0.9824, test acc = 0.9797, train loss = 0.0038, val loss = 0.0872, test loss = 0.1159 (111.83 s)\n",
            "18500: train acc = 0.9991, val acc = 0.9844, test acc = 0.9810, train loss = 0.0025, val loss = 0.0846, test loss = 0.1121 (112.46 s)\n",
            "18600: train acc = 0.9987, val acc = 0.9846, test acc = 0.9809, train loss = 0.0042, val loss = 0.0904, test loss = 0.1229 (113.16 s)\n",
            "18700: train acc = 0.9985, val acc = 0.9842, test acc = 0.9795, train loss = 0.0046, val loss = 0.0860, test loss = 0.1170 (113.65 s)\n",
            "18800: train acc = 0.9971, val acc = 0.9812, test acc = 0.9785, train loss = 0.0080, val loss = 0.1079, test loss = 0.1334 (114.20 s)\n",
            "18900: train acc = 0.9952, val acc = 0.9796, test acc = 0.9774, train loss = 0.0170, val loss = 0.1093, test loss = 0.1404 (114.84 s)\n",
            "19000: train acc = 0.9965, val acc = 0.9812, test acc = 0.9794, train loss = 0.0105, val loss = 0.1067, test loss = 0.1153 (115.54 s)\n",
            "19100: train acc = 0.9974, val acc = 0.9812, test acc = 0.9798, train loss = 0.0071, val loss = 0.0975, test loss = 0.1187 (116.02 s)\n",
            "19200: train acc = 0.9985, val acc = 0.9826, test acc = 0.9800, train loss = 0.0043, val loss = 0.0945, test loss = 0.1145 (116.57 s)\n",
            "19300: train acc = 0.9980, val acc = 0.9824, test acc = 0.9809, train loss = 0.0059, val loss = 0.1031, test loss = 0.1033 (117.20 s)\n",
            "19400: train acc = 0.9972, val acc = 0.9788, test acc = 0.9776, train loss = 0.0098, val loss = 0.1283, test loss = 0.1326 (117.90 s)\n",
            "19500: train acc = 0.9978, val acc = 0.9832, test acc = 0.9790, train loss = 0.0064, val loss = 0.1066, test loss = 0.1209 (118.40 s)\n",
            "19600: train acc = 0.9968, val acc = 0.9796, test acc = 0.9794, train loss = 0.0096, val loss = 0.1114, test loss = 0.1342 (118.97 s)\n",
            "19700: train acc = 0.9988, val acc = 0.9834, test acc = 0.9808, train loss = 0.0042, val loss = 0.0989, test loss = 0.1182 (119.61 s)\n",
            "19800: train acc = 0.9979, val acc = 0.9788, test acc = 0.9796, train loss = 0.0057, val loss = 0.1184, test loss = 0.1283 (120.33 s)\n",
            "19900: train acc = 0.9946, val acc = 0.9784, test acc = 0.9755, train loss = 0.0173, val loss = 0.1287, test loss = 0.1445 (120.82 s)\n",
            "20000: train acc = 0.9979, val acc = 0.9806, test acc = 0.9790, train loss = 0.0060, val loss = 0.1108, test loss = 0.1357 (121.37 s)\n",
            "20100: train acc = 0.9983, val acc = 0.9814, test acc = 0.9790, train loss = 0.0049, val loss = 0.1034, test loss = 0.1272 (122.00 s)\n",
            "20200: train acc = 0.9979, val acc = 0.9800, test acc = 0.9805, train loss = 0.0058, val loss = 0.1063, test loss = 0.1322 (122.70 s)\n",
            "20300: train acc = 0.9983, val acc = 0.9816, test acc = 0.9795, train loss = 0.0056, val loss = 0.1086, test loss = 0.1307 (123.21 s)\n",
            "20400: train acc = 0.9983, val acc = 0.9804, test acc = 0.9797, train loss = 0.0054, val loss = 0.0970, test loss = 0.1228 (123.75 s)\n",
            "20500: train acc = 0.9978, val acc = 0.9830, test acc = 0.9798, train loss = 0.0076, val loss = 0.1021, test loss = 0.1313 (124.39 s)\n",
            "20600: train acc = 0.9982, val acc = 0.9810, test acc = 0.9806, train loss = 0.0060, val loss = 0.1076, test loss = 0.1220 (125.11 s)\n",
            "20700: train acc = 0.9980, val acc = 0.9814, test acc = 0.9788, train loss = 0.0058, val loss = 0.1032, test loss = 0.1251 (125.59 s)\n",
            "20800: train acc = 0.9984, val acc = 0.9840, test acc = 0.9788, train loss = 0.0053, val loss = 0.0887, test loss = 0.1256 (126.15 s)\n",
            "20900: train acc = 0.9983, val acc = 0.9842, test acc = 0.9793, train loss = 0.0046, val loss = 0.0952, test loss = 0.1248 (126.78 s)\n",
            "21000: train acc = 0.9992, val acc = 0.9830, test acc = 0.9806, train loss = 0.0026, val loss = 0.1045, test loss = 0.1156 (127.49 s)\n",
            "21100: train acc = 0.9980, val acc = 0.9806, test acc = 0.9785, train loss = 0.0060, val loss = 0.1285, test loss = 0.1301 (127.98 s)\n",
            "21200: train acc = 0.9979, val acc = 0.9820, test acc = 0.9795, train loss = 0.0066, val loss = 0.1140, test loss = 0.1193 (128.55 s)\n",
            "21300: train acc = 0.9991, val acc = 0.9802, test acc = 0.9811, train loss = 0.0025, val loss = 0.1230, test loss = 0.1104 (129.20 s)\n",
            "21400: train acc = 0.9988, val acc = 0.9828, test acc = 0.9812, train loss = 0.0037, val loss = 0.1097, test loss = 0.1175 (129.90 s)\n",
            "21500: train acc = 0.9983, val acc = 0.9822, test acc = 0.9819, train loss = 0.0046, val loss = 0.1216, test loss = 0.1177 (130.39 s)\n",
            "21600: train acc = 0.9969, val acc = 0.9822, test acc = 0.9793, train loss = 0.0104, val loss = 0.1146, test loss = 0.1380 (130.93 s)\n",
            "21700: train acc = 0.9978, val acc = 0.9810, test acc = 0.9804, train loss = 0.0061, val loss = 0.1168, test loss = 0.1223 (131.55 s)\n",
            "21800: train acc = 0.9985, val acc = 0.9840, test acc = 0.9810, train loss = 0.0042, val loss = 0.1108, test loss = 0.1153 (132.27 s)\n",
            "21900: train acc = 0.9975, val acc = 0.9804, test acc = 0.9780, train loss = 0.0082, val loss = 0.1256, test loss = 0.1355 (132.78 s)\n",
            "22000: train acc = 0.9989, val acc = 0.9826, test acc = 0.9799, train loss = 0.0031, val loss = 0.1150, test loss = 0.1138 (133.32 s)\n",
            "22100: train acc = 0.9977, val acc = 0.9816, test acc = 0.9790, train loss = 0.0079, val loss = 0.1229, test loss = 0.1286 (133.95 s)\n",
            "22200: train acc = 0.9989, val acc = 0.9842, test acc = 0.9820, train loss = 0.0043, val loss = 0.1139, test loss = 0.1111 (134.67 s)\n",
            "22300: train acc = 0.9992, val acc = 0.9842, test acc = 0.9821, train loss = 0.0033, val loss = 0.0999, test loss = 0.1120 (135.16 s)\n",
            "22400: train acc = 0.9983, val acc = 0.9842, test acc = 0.9811, train loss = 0.0057, val loss = 0.1164, test loss = 0.1205 (135.72 s)\n",
            "22500: train acc = 0.9983, val acc = 0.9820, test acc = 0.9813, train loss = 0.0055, val loss = 0.1105, test loss = 0.1180 (136.34 s)\n",
            "22600: train acc = 0.9967, val acc = 0.9796, test acc = 0.9770, train loss = 0.0134, val loss = 0.1376, test loss = 0.1483 (137.04 s)\n",
            "22700: train acc = 0.9979, val acc = 0.9808, test acc = 0.9812, train loss = 0.0067, val loss = 0.1229, test loss = 0.1224 (137.53 s)\n",
            "22800: train acc = 0.9909, val acc = 0.9730, test acc = 0.9720, train loss = 0.0308, val loss = 0.1791, test loss = 0.1810 (138.07 s)\n",
            "22900: train acc = 0.9960, val acc = 0.9790, test acc = 0.9767, train loss = 0.0125, val loss = 0.1303, test loss = 0.1585 (138.75 s)\n",
            "23000: train acc = 0.9987, val acc = 0.9796, test acc = 0.9803, train loss = 0.0041, val loss = 0.1153, test loss = 0.1228 (139.44 s)\n",
            "23100: train acc = 0.9984, val acc = 0.9826, test acc = 0.9810, train loss = 0.0050, val loss = 0.1067, test loss = 0.1201 (139.92 s)\n",
            "23200: train acc = 0.9983, val acc = 0.9832, test acc = 0.9815, train loss = 0.0053, val loss = 0.1118, test loss = 0.1138 (140.49 s)\n",
            "23300: train acc = 0.9970, val acc = 0.9780, test acc = 0.9784, train loss = 0.0094, val loss = 0.1318, test loss = 0.1220 (141.10 s)\n",
            "23400: train acc = 0.9986, val acc = 0.9826, test acc = 0.9815, train loss = 0.0045, val loss = 0.1175, test loss = 0.1084 (141.80 s)\n",
            "23500: train acc = 0.9977, val acc = 0.9818, test acc = 0.9815, train loss = 0.0067, val loss = 0.1169, test loss = 0.1131 (142.29 s)\n",
            "23600: train acc = 0.9977, val acc = 0.9818, test acc = 0.9779, train loss = 0.0088, val loss = 0.1229, test loss = 0.1364 (142.84 s)\n",
            "23700: train acc = 0.9983, val acc = 0.9834, test acc = 0.9799, train loss = 0.0058, val loss = 0.1011, test loss = 0.1182 (143.47 s)\n",
            "23800: train acc = 0.9983, val acc = 0.9834, test acc = 0.9801, train loss = 0.0054, val loss = 0.1060, test loss = 0.1261 (144.17 s)\n",
            "23900: train acc = 0.9986, val acc = 0.9826, test acc = 0.9815, train loss = 0.0045, val loss = 0.1000, test loss = 0.1207 (144.66 s)\n",
            "24000: train acc = 0.9989, val acc = 0.9826, test acc = 0.9818, train loss = 0.0035, val loss = 0.1169, test loss = 0.1144 (145.22 s)\n",
            "24100: train acc = 0.9992, val acc = 0.9864, test acc = 0.9834, train loss = 0.0028, val loss = 0.1040, test loss = 0.1132 (145.84 s)\n",
            "24200: train acc = 0.9990, val acc = 0.9830, test acc = 0.9824, train loss = 0.0029, val loss = 0.1144, test loss = 0.1085 (146.55 s)\n",
            "24300: train acc = 0.9981, val acc = 0.9826, test acc = 0.9812, train loss = 0.0081, val loss = 0.1146, test loss = 0.1142 (147.05 s)\n",
            "24400: train acc = 0.9988, val acc = 0.9836, test acc = 0.9820, train loss = 0.0039, val loss = 0.1117, test loss = 0.1122 (147.61 s)\n",
            "24500: train acc = 0.9981, val acc = 0.9832, test acc = 0.9794, train loss = 0.0063, val loss = 0.1142, test loss = 0.1330 (148.23 s)\n",
            "24600: train acc = 0.9981, val acc = 0.9812, test acc = 0.9798, train loss = 0.0062, val loss = 0.1198, test loss = 0.1270 (148.94 s)\n",
            "24700: train acc = 0.9978, val acc = 0.9820, test acc = 0.9809, train loss = 0.0076, val loss = 0.1209, test loss = 0.1297 (149.44 s)\n",
            "24800: train acc = 0.9986, val acc = 0.9834, test acc = 0.9823, train loss = 0.0052, val loss = 0.1107, test loss = 0.1223 (150.02 s)\n",
            "24900: train acc = 0.9984, val acc = 0.9806, test acc = 0.9820, train loss = 0.0069, val loss = 0.1123, test loss = 0.1257 (150.68 s)\n",
            "25000: train acc = 0.9965, val acc = 0.9798, test acc = 0.9780, train loss = 0.0132, val loss = 0.1293, test loss = 0.1442 (151.39 s)\n",
            "25100: train acc = 0.9965, val acc = 0.9796, test acc = 0.9803, train loss = 0.0135, val loss = 0.1466, test loss = 0.1456 (151.88 s)\n",
            "25200: train acc = 0.9973, val acc = 0.9802, test acc = 0.9778, train loss = 0.0085, val loss = 0.1330, test loss = 0.1436 (152.42 s)\n",
            "25300: train acc = 0.9965, val acc = 0.9798, test acc = 0.9793, train loss = 0.0121, val loss = 0.1456, test loss = 0.1354 (153.04 s)\n",
            "25400: train acc = 0.9983, val acc = 0.9816, test acc = 0.9815, train loss = 0.0050, val loss = 0.1150, test loss = 0.1265 (153.77 s)\n",
            "25500: train acc = 0.9985, val acc = 0.9852, test acc = 0.9807, train loss = 0.0055, val loss = 0.0994, test loss = 0.1333 (154.25 s)\n",
            "25600: train acc = 0.9979, val acc = 0.9810, test acc = 0.9789, train loss = 0.0071, val loss = 0.1010, test loss = 0.1361 (154.81 s)\n",
            "25700: train acc = 0.9985, val acc = 0.9854, test acc = 0.9818, train loss = 0.0049, val loss = 0.1084, test loss = 0.1321 (155.44 s)\n",
            "25800: train acc = 0.9992, val acc = 0.9842, test acc = 0.9821, train loss = 0.0028, val loss = 0.1058, test loss = 0.1205 (156.14 s)\n",
            "25900: train acc = 0.9983, val acc = 0.9812, test acc = 0.9813, train loss = 0.0055, val loss = 0.1216, test loss = 0.1318 (156.62 s)\n",
            "26000: train acc = 0.9975, val acc = 0.9786, test acc = 0.9817, train loss = 0.0082, val loss = 0.1326, test loss = 0.1316 (157.17 s)\n",
            "26100: train acc = 0.9969, val acc = 0.9818, test acc = 0.9799, train loss = 0.0119, val loss = 0.1285, test loss = 0.1303 (157.82 s)\n",
            "26200: train acc = 0.9982, val acc = 0.9826, test acc = 0.9797, train loss = 0.0058, val loss = 0.1161, test loss = 0.1357 (158.55 s)\n",
            "26300: train acc = 0.9979, val acc = 0.9788, test acc = 0.9808, train loss = 0.0072, val loss = 0.1280, test loss = 0.1309 (159.04 s)\n",
            "26400: train acc = 0.9981, val acc = 0.9824, test acc = 0.9801, train loss = 0.0063, val loss = 0.1138, test loss = 0.1296 (159.60 s)\n",
            "26500: train acc = 0.9979, val acc = 0.9816, test acc = 0.9785, train loss = 0.0081, val loss = 0.1225, test loss = 0.1346 (160.25 s)\n",
            "26600: train acc = 0.9985, val acc = 0.9838, test acc = 0.9830, train loss = 0.0053, val loss = 0.1124, test loss = 0.1151 (160.96 s)\n",
            "26700: train acc = 0.9989, val acc = 0.9844, test acc = 0.9832, train loss = 0.0035, val loss = 0.1132, test loss = 0.1103 (161.45 s)\n",
            "26800: train acc = 0.9993, val acc = 0.9842, test acc = 0.9821, train loss = 0.0028, val loss = 0.1073, test loss = 0.1136 (162.00 s)\n",
            "26900: train acc = 0.9989, val acc = 0.9812, test acc = 0.9801, train loss = 0.0037, val loss = 0.1124, test loss = 0.1239 (162.64 s)\n",
            "27000: train acc = 0.9984, val acc = 0.9840, test acc = 0.9797, train loss = 0.0048, val loss = 0.1036, test loss = 0.1363 (163.35 s)\n",
            "27100: train acc = 0.9973, val acc = 0.9796, test acc = 0.9796, train loss = 0.0099, val loss = 0.1268, test loss = 0.1403 (163.85 s)\n",
            "27200: train acc = 0.9988, val acc = 0.9838, test acc = 0.9814, train loss = 0.0037, val loss = 0.1176, test loss = 0.1303 (164.40 s)\n",
            "27300: train acc = 0.9995, val acc = 0.9866, test acc = 0.9814, train loss = 0.0012, val loss = 0.1021, test loss = 0.1245 (165.04 s)\n",
            "27400: train acc = 0.9994, val acc = 0.9862, test acc = 0.9817, train loss = 0.0017, val loss = 0.0973, test loss = 0.1238 (165.75 s)\n",
            "27500: train acc = 0.9994, val acc = 0.9854, test acc = 0.9796, train loss = 0.0016, val loss = 0.1005, test loss = 0.1206 (166.24 s)\n",
            "27600: train acc = 0.9995, val acc = 0.9828, test acc = 0.9826, train loss = 0.0016, val loss = 0.1106, test loss = 0.1223 (166.80 s)\n",
            "27700: train acc = 0.9973, val acc = 0.9826, test acc = 0.9803, train loss = 0.0093, val loss = 0.1205, test loss = 0.1514 (167.42 s)\n",
            "27800: train acc = 0.9987, val acc = 0.9814, test acc = 0.9804, train loss = 0.0044, val loss = 0.1136, test loss = 0.1283 (168.12 s)\n",
            "27900: train acc = 0.9982, val acc = 0.9824, test acc = 0.9805, train loss = 0.0063, val loss = 0.1151, test loss = 0.1259 (168.61 s)\n",
            "28000: train acc = 0.9955, val acc = 0.9778, test acc = 0.9779, train loss = 0.0149, val loss = 0.1388, test loss = 0.1362 (169.16 s)\n",
            "28100: train acc = 0.9989, val acc = 0.9812, test acc = 0.9806, train loss = 0.0036, val loss = 0.1103, test loss = 0.1268 (169.83 s)\n",
            "28200: train acc = 0.9976, val acc = 0.9828, test acc = 0.9791, train loss = 0.0064, val loss = 0.1134, test loss = 0.1351 (170.53 s)\n",
            "28300: train acc = 0.9974, val acc = 0.9790, test acc = 0.9779, train loss = 0.0081, val loss = 0.1300, test loss = 0.1367 (171.02 s)\n",
            "28400: train acc = 0.9984, val acc = 0.9828, test acc = 0.9810, train loss = 0.0051, val loss = 0.1184, test loss = 0.1276 (171.57 s)\n",
            "28500: train acc = 0.9985, val acc = 0.9822, test acc = 0.9807, train loss = 0.0050, val loss = 0.1226, test loss = 0.1320 (172.20 s)\n",
            "28600: train acc = 0.9986, val acc = 0.9822, test acc = 0.9823, train loss = 0.0043, val loss = 0.1304, test loss = 0.1230 (172.90 s)\n",
            "28700: train acc = 0.9981, val acc = 0.9804, test acc = 0.9805, train loss = 0.0061, val loss = 0.1308, test loss = 0.1299 (173.39 s)\n",
            "28800: train acc = 0.9987, val acc = 0.9822, test acc = 0.9817, train loss = 0.0053, val loss = 0.1297, test loss = 0.1216 (173.93 s)\n",
            "28900: train acc = 0.9990, val acc = 0.9816, test acc = 0.9833, train loss = 0.0035, val loss = 0.1297, test loss = 0.1138 (174.57 s)\n",
            "29000: train acc = 0.9981, val acc = 0.9800, test acc = 0.9812, train loss = 0.0074, val loss = 0.1324, test loss = 0.1295 (175.30 s)\n",
            "29100: train acc = 0.9990, val acc = 0.9828, test acc = 0.9807, train loss = 0.0030, val loss = 0.1122, test loss = 0.1219 (175.79 s)\n",
            "29200: train acc = 0.9992, val acc = 0.9824, test acc = 0.9817, train loss = 0.0030, val loss = 0.1109, test loss = 0.1262 (176.34 s)\n",
            "29300: train acc = 0.9989, val acc = 0.9832, test acc = 0.9816, train loss = 0.0035, val loss = 0.1071, test loss = 0.1178 (176.98 s)\n",
            "29400: train acc = 0.9993, val acc = 0.9848, test acc = 0.9825, train loss = 0.0022, val loss = 0.1076, test loss = 0.1194 (177.70 s)\n",
            "29500: train acc = 0.9996, val acc = 0.9856, test acc = 0.9826, train loss = 0.0015, val loss = 0.1031, test loss = 0.1149 (178.21 s)\n",
            "29600: train acc = 0.9993, val acc = 0.9832, test acc = 0.9817, train loss = 0.0020, val loss = 0.1069, test loss = 0.1197 (178.78 s)\n",
            "29700: train acc = 0.9995, val acc = 0.9846, test acc = 0.9834, train loss = 0.0014, val loss = 0.1088, test loss = 0.1147 (179.42 s)\n",
            "29800: train acc = 0.9996, val acc = 0.9852, test acc = 0.9821, train loss = 0.0012, val loss = 0.1099, test loss = 0.1100 (180.14 s)\n",
            "29900: train acc = 0.9991, val acc = 0.9810, test acc = 0.9815, train loss = 0.0036, val loss = 0.1218, test loss = 0.1328 (180.65 s)\n",
            "30000: train acc = 0.9984, val acc = 0.9810, test acc = 0.9804, train loss = 0.0050, val loss = 0.1145, test loss = 0.1349 (181.21 s)\n",
            "30100: train acc = 0.9984, val acc = 0.9814, test acc = 0.9801, train loss = 0.0048, val loss = 0.1252, test loss = 0.1280 (181.85 s)\n",
            "30200: train acc = 0.9985, val acc = 0.9822, test acc = 0.9803, train loss = 0.0061, val loss = 0.1173, test loss = 0.1321 (182.61 s)\n",
            "30300: train acc = 0.9975, val acc = 0.9810, test acc = 0.9796, train loss = 0.0098, val loss = 0.1166, test loss = 0.1429 (183.16 s)\n",
            "30400: train acc = 0.9986, val acc = 0.9820, test acc = 0.9799, train loss = 0.0044, val loss = 0.1107, test loss = 0.1346 (183.75 s)\n",
            "30500: train acc = 0.9992, val acc = 0.9836, test acc = 0.9827, train loss = 0.0021, val loss = 0.1028, test loss = 0.1184 (184.41 s)\n",
            "30600: train acc = 0.9988, val acc = 0.9828, test acc = 0.9817, train loss = 0.0040, val loss = 0.1045, test loss = 0.1355 (185.14 s)\n",
            "30700: train acc = 0.9991, val acc = 0.9836, test acc = 0.9819, train loss = 0.0025, val loss = 0.1056, test loss = 0.1243 (185.67 s)\n",
            "30800: train acc = 0.9987, val acc = 0.9830, test acc = 0.9818, train loss = 0.0043, val loss = 0.1191, test loss = 0.1310 (186.24 s)\n",
            "30900: train acc = 0.9990, val acc = 0.9820, test acc = 0.9803, train loss = 0.0037, val loss = 0.1169, test loss = 0.1503 (186.89 s)\n",
            "31000: train acc = 0.9961, val acc = 0.9778, test acc = 0.9774, train loss = 0.0129, val loss = 0.1508, test loss = 0.1622 (187.62 s)\n",
            "31100: train acc = 0.9972, val acc = 0.9792, test acc = 0.9795, train loss = 0.0096, val loss = 0.1419, test loss = 0.1469 (188.14 s)\n",
            "31200: train acc = 0.9987, val acc = 0.9832, test acc = 0.9823, train loss = 0.0035, val loss = 0.1198, test loss = 0.1405 (188.73 s)\n",
            "31300: train acc = 0.9990, val acc = 0.9868, test acc = 0.9818, train loss = 0.0033, val loss = 0.1067, test loss = 0.1290 (189.39 s)\n",
            "31400: train acc = 0.9992, val acc = 0.9826, test acc = 0.9824, train loss = 0.0025, val loss = 0.1248, test loss = 0.1274 (190.13 s)\n",
            "31500: train acc = 0.9986, val acc = 0.9810, test acc = 0.9819, train loss = 0.0043, val loss = 0.1321, test loss = 0.1321 (190.63 s)\n",
            "31600: train acc = 0.9994, val acc = 0.9834, test acc = 0.9826, train loss = 0.0022, val loss = 0.1204, test loss = 0.1214 (191.20 s)\n",
            "31700: train acc = 0.9995, val acc = 0.9828, test acc = 0.9821, train loss = 0.0022, val loss = 0.1198, test loss = 0.1197 (191.87 s)\n",
            "31800: train acc = 0.9989, val acc = 0.9814, test acc = 0.9833, train loss = 0.0037, val loss = 0.1357, test loss = 0.1196 (192.61 s)\n",
            "31900: train acc = 0.9989, val acc = 0.9826, test acc = 0.9814, train loss = 0.0041, val loss = 0.1192, test loss = 0.1367 (193.11 s)\n",
            "32000: train acc = 0.9991, val acc = 0.9814, test acc = 0.9816, train loss = 0.0031, val loss = 0.1349, test loss = 0.1196 (193.68 s)\n",
            "32100: train acc = 0.9977, val acc = 0.9796, test acc = 0.9821, train loss = 0.0083, val loss = 0.1512, test loss = 0.1230 (194.33 s)\n",
            "32200: train acc = 0.9987, val acc = 0.9834, test acc = 0.9804, train loss = 0.0042, val loss = 0.1357, test loss = 0.1398 (195.05 s)\n",
            "32300: train acc = 0.9989, val acc = 0.9832, test acc = 0.9812, train loss = 0.0032, val loss = 0.1214, test loss = 0.1334 (195.56 s)\n",
            "32400: train acc = 0.9993, val acc = 0.9840, test acc = 0.9830, train loss = 0.0021, val loss = 0.1206, test loss = 0.1265 (196.13 s)\n",
            "32500: train acc = 0.9989, val acc = 0.9814, test acc = 0.9824, train loss = 0.0036, val loss = 0.1373, test loss = 0.1204 (196.78 s)\n",
            "32600: train acc = 0.9986, val acc = 0.9818, test acc = 0.9796, train loss = 0.0041, val loss = 0.1231, test loss = 0.1468 (197.50 s)\n",
            "32700: train acc = 0.9988, val acc = 0.9818, test acc = 0.9802, train loss = 0.0036, val loss = 0.1283, test loss = 0.1326 (197.99 s)\n",
            "32800: train acc = 0.9968, val acc = 0.9798, test acc = 0.9793, train loss = 0.0131, val loss = 0.1357, test loss = 0.1480 (198.55 s)\n",
            "32900: train acc = 0.9977, val acc = 0.9802, test acc = 0.9803, train loss = 0.0073, val loss = 0.1340, test loss = 0.1408 (199.18 s)\n",
            "33000: train acc = 0.9988, val acc = 0.9810, test acc = 0.9806, train loss = 0.0043, val loss = 0.1228, test loss = 0.1296 (199.89 s)\n",
            "33100: train acc = 0.9977, val acc = 0.9798, test acc = 0.9804, train loss = 0.0104, val loss = 0.1514, test loss = 0.1523 (200.41 s)\n",
            "33200: train acc = 0.9957, val acc = 0.9810, test acc = 0.9770, train loss = 0.0196, val loss = 0.1730, test loss = 0.1930 (200.97 s)\n",
            "33300: train acc = 0.9971, val acc = 0.9836, test acc = 0.9785, train loss = 0.0100, val loss = 0.1448, test loss = 0.1691 (201.60 s)\n",
            "33400: train acc = 0.9986, val acc = 0.9824, test acc = 0.9796, train loss = 0.0052, val loss = 0.1337, test loss = 0.1507 (202.31 s)\n",
            "33500: train acc = 0.9970, val acc = 0.9820, test acc = 0.9778, train loss = 0.0111, val loss = 0.1418, test loss = 0.1640 (202.81 s)\n",
            "33600: train acc = 0.9980, val acc = 0.9822, test acc = 0.9792, train loss = 0.0075, val loss = 0.1502, test loss = 0.1525 (203.39 s)\n",
            "33700: train acc = 0.9989, val acc = 0.9826, test acc = 0.9811, train loss = 0.0045, val loss = 0.1376, test loss = 0.1376 (204.05 s)\n",
            "33800: train acc = 0.9989, val acc = 0.9824, test acc = 0.9812, train loss = 0.0037, val loss = 0.1420, test loss = 0.1383 (204.78 s)\n",
            "33900: train acc = 0.9966, val acc = 0.9792, test acc = 0.9768, train loss = 0.0129, val loss = 0.1585, test loss = 0.1888 (205.28 s)\n",
            "34000: train acc = 0.9988, val acc = 0.9840, test acc = 0.9805, train loss = 0.0046, val loss = 0.1271, test loss = 0.1462 (205.84 s)\n",
            "34100: train acc = 0.9990, val acc = 0.9838, test acc = 0.9810, train loss = 0.0033, val loss = 0.1261, test loss = 0.1356 (206.50 s)\n",
            "34200: train acc = 0.9988, val acc = 0.9830, test acc = 0.9804, train loss = 0.0037, val loss = 0.1255, test loss = 0.1420 (207.20 s)\n",
            "34300: train acc = 0.9993, val acc = 0.9834, test acc = 0.9812, train loss = 0.0022, val loss = 0.1342, test loss = 0.1334 (207.69 s)\n",
            "34400: train acc = 0.9995, val acc = 0.9844, test acc = 0.9817, train loss = 0.0015, val loss = 0.1310, test loss = 0.1343 (208.25 s)\n",
            "34500: train acc = 0.9996, val acc = 0.9846, test acc = 0.9824, train loss = 0.0013, val loss = 0.1346, test loss = 0.1318 (208.88 s)\n",
            "34600: train acc = 0.9995, val acc = 0.9846, test acc = 0.9813, train loss = 0.0018, val loss = 0.1299, test loss = 0.1299 (209.59 s)\n",
            "34700: train acc = 0.9992, val acc = 0.9854, test acc = 0.9811, train loss = 0.0032, val loss = 0.1314, test loss = 0.1446 (210.09 s)\n",
            "34800: train acc = 0.9986, val acc = 0.9816, test acc = 0.9807, train loss = 0.0042, val loss = 0.1413, test loss = 0.1582 (210.67 s)\n",
            "34900: train acc = 0.9988, val acc = 0.9824, test acc = 0.9798, train loss = 0.0038, val loss = 0.1492, test loss = 0.1521 (211.32 s)\n",
            "35000: train acc = 0.9984, val acc = 0.9818, test acc = 0.9793, train loss = 0.0059, val loss = 0.1397, test loss = 0.1538 (212.06 s)\n",
            "35100: train acc = 0.9982, val acc = 0.9822, test acc = 0.9783, train loss = 0.0075, val loss = 0.1396, test loss = 0.1671 (212.55 s)\n",
            "35200: train acc = 0.9988, val acc = 0.9832, test acc = 0.9815, train loss = 0.0045, val loss = 0.1437, test loss = 0.1478 (213.13 s)\n",
            "35300: train acc = 0.9959, val acc = 0.9796, test acc = 0.9779, train loss = 0.0176, val loss = 0.1707, test loss = 0.1547 (213.77 s)\n",
            "35400: train acc = 0.9984, val acc = 0.9832, test acc = 0.9808, train loss = 0.0061, val loss = 0.1412, test loss = 0.1439 (214.48 s)\n",
            "35500: train acc = 0.9979, val acc = 0.9812, test acc = 0.9808, train loss = 0.0071, val loss = 0.1436, test loss = 0.1417 (214.97 s)\n",
            "35600: train acc = 0.9990, val acc = 0.9824, test acc = 0.9814, train loss = 0.0027, val loss = 0.1441, test loss = 0.1307 (215.54 s)\n",
            "35700: train acc = 0.9989, val acc = 0.9814, test acc = 0.9813, train loss = 0.0038, val loss = 0.1417, test loss = 0.1353 (216.19 s)\n",
            "35800: train acc = 0.9988, val acc = 0.9816, test acc = 0.9798, train loss = 0.0035, val loss = 0.1336, test loss = 0.1395 (216.91 s)\n",
            "35900: train acc = 0.9989, val acc = 0.9814, test acc = 0.9803, train loss = 0.0036, val loss = 0.1398, test loss = 0.1508 (217.41 s)\n",
            "36000: train acc = 0.9993, val acc = 0.9822, test acc = 0.9801, train loss = 0.0027, val loss = 0.1340, test loss = 0.1441 (217.96 s)\n",
            "36100: train acc = 0.9983, val acc = 0.9820, test acc = 0.9816, train loss = 0.0066, val loss = 0.1431, test loss = 0.1301 (218.60 s)\n",
            "36200: train acc = 0.9993, val acc = 0.9836, test acc = 0.9817, train loss = 0.0025, val loss = 0.1437, test loss = 0.1329 (219.30 s)\n",
            "36300: train acc = 0.9994, val acc = 0.9834, test acc = 0.9832, train loss = 0.0025, val loss = 0.1429, test loss = 0.1308 (219.82 s)\n",
            "36400: train acc = 0.9985, val acc = 0.9816, test acc = 0.9828, train loss = 0.0038, val loss = 0.1530, test loss = 0.1297 (220.41 s)\n",
            "36500: train acc = 0.9980, val acc = 0.9802, test acc = 0.9815, train loss = 0.0084, val loss = 0.1674, test loss = 0.1400 (221.04 s)\n",
            "36600: train acc = 0.9984, val acc = 0.9812, test acc = 0.9813, train loss = 0.0052, val loss = 0.1663, test loss = 0.1446 (221.77 s)\n",
            "36700: train acc = 0.9989, val acc = 0.9816, test acc = 0.9826, train loss = 0.0046, val loss = 0.1642, test loss = 0.1363 (222.28 s)\n",
            "36800: train acc = 0.9989, val acc = 0.9808, test acc = 0.9815, train loss = 0.0030, val loss = 0.1619, test loss = 0.1352 (222.83 s)\n",
            "36900: train acc = 0.9993, val acc = 0.9814, test acc = 0.9830, train loss = 0.0020, val loss = 0.1531, test loss = 0.1252 (223.47 s)\n",
            "37000: train acc = 0.9984, val acc = 0.9816, test acc = 0.9813, train loss = 0.0056, val loss = 0.1550, test loss = 0.1349 (224.21 s)\n",
            "37100: train acc = 0.9995, val acc = 0.9828, test acc = 0.9832, train loss = 0.0015, val loss = 0.1524, test loss = 0.1238 (224.71 s)\n",
            "37200: train acc = 0.9995, val acc = 0.9826, test acc = 0.9824, train loss = 0.0021, val loss = 0.1569, test loss = 0.1250 (225.26 s)\n",
            "37300: train acc = 0.9975, val acc = 0.9794, test acc = 0.9808, train loss = 0.0091, val loss = 0.1844, test loss = 0.1485 (225.96 s)\n",
            "37400: train acc = 0.9979, val acc = 0.9798, test acc = 0.9821, train loss = 0.0073, val loss = 0.1635, test loss = 0.1412 (226.67 s)\n",
            "37500: train acc = 0.9978, val acc = 0.9802, test acc = 0.9799, train loss = 0.0078, val loss = 0.1600, test loss = 0.1482 (227.16 s)\n",
            "37600: train acc = 0.9988, val acc = 0.9818, test acc = 0.9817, train loss = 0.0039, val loss = 0.1489, test loss = 0.1331 (227.75 s)\n",
            "37700: train acc = 0.9990, val acc = 0.9814, test acc = 0.9827, train loss = 0.0033, val loss = 0.1508, test loss = 0.1272 (228.39 s)\n",
            "37800: train acc = 0.9986, val acc = 0.9832, test acc = 0.9803, train loss = 0.0066, val loss = 0.1345, test loss = 0.1442 (229.10 s)\n",
            "37900: train acc = 0.9987, val acc = 0.9820, test acc = 0.9814, train loss = 0.0044, val loss = 0.1517, test loss = 0.1311 (229.62 s)\n",
            "38000: train acc = 0.9968, val acc = 0.9796, test acc = 0.9792, train loss = 0.0141, val loss = 0.1685, test loss = 0.1679 (230.19 s)\n",
            "38100: train acc = 0.9984, val acc = 0.9788, test acc = 0.9812, train loss = 0.0063, val loss = 0.1675, test loss = 0.1482 (230.83 s)\n",
            "38200: train acc = 0.9983, val acc = 0.9830, test acc = 0.9812, train loss = 0.0061, val loss = 0.1561, test loss = 0.1320 (231.54 s)\n",
            "38300: train acc = 0.9984, val acc = 0.9814, test acc = 0.9808, train loss = 0.0056, val loss = 0.1539, test loss = 0.1443 (232.03 s)\n",
            "38400: train acc = 0.9982, val acc = 0.9804, test acc = 0.9833, train loss = 0.0065, val loss = 0.1715, test loss = 0.1365 (232.61 s)\n",
            "38500: train acc = 0.9993, val acc = 0.9830, test acc = 0.9838, train loss = 0.0022, val loss = 0.1388, test loss = 0.1303 (233.24 s)\n",
            "38600: train acc = 0.9994, val acc = 0.9828, test acc = 0.9827, train loss = 0.0020, val loss = 0.1403, test loss = 0.1315 (233.96 s)\n",
            "38700: train acc = 0.9990, val acc = 0.9828, test acc = 0.9837, train loss = 0.0036, val loss = 0.1331, test loss = 0.1253 (234.46 s)\n",
            "38800: train acc = 0.9991, val acc = 0.9814, test acc = 0.9828, train loss = 0.0028, val loss = 0.1484, test loss = 0.1370 (235.02 s)\n",
            "38900: train acc = 0.9987, val acc = 0.9804, test acc = 0.9813, train loss = 0.0044, val loss = 0.1720, test loss = 0.1537 (235.67 s)\n",
            "39000: train acc = 0.9988, val acc = 0.9814, test acc = 0.9817, train loss = 0.0045, val loss = 0.1556, test loss = 0.1478 (236.37 s)\n",
            "39100: train acc = 0.9960, val acc = 0.9802, test acc = 0.9799, train loss = 0.0173, val loss = 0.1878, test loss = 0.1659 (236.88 s)\n",
            "39200: train acc = 0.9994, val acc = 0.9842, test acc = 0.9812, train loss = 0.0022, val loss = 0.1375, test loss = 0.1347 (237.49 s)\n",
            "39300: train acc = 0.9989, val acc = 0.9840, test acc = 0.9830, train loss = 0.0035, val loss = 0.1304, test loss = 0.1338 (238.18 s)\n",
            "39400: train acc = 0.9984, val acc = 0.9818, test acc = 0.9816, train loss = 0.0060, val loss = 0.1392, test loss = 0.1560 (238.92 s)\n",
            "39500: train acc = 0.9994, val acc = 0.9840, test acc = 0.9833, train loss = 0.0019, val loss = 0.1228, test loss = 0.1359 (239.43 s)\n",
            "39600: train acc = 0.9991, val acc = 0.9818, test acc = 0.9837, train loss = 0.0024, val loss = 0.1426, test loss = 0.1320 (239.99 s)\n",
            "39700: train acc = 0.9991, val acc = 0.9824, test acc = 0.9821, train loss = 0.0029, val loss = 0.1408, test loss = 0.1350 (240.64 s)\n",
            "39800: train acc = 0.9986, val acc = 0.9824, test acc = 0.9843, train loss = 0.0048, val loss = 0.1458, test loss = 0.1354 (241.37 s)\n",
            "39900: train acc = 0.9985, val acc = 0.9820, test acc = 0.9819, train loss = 0.0064, val loss = 0.1523, test loss = 0.1416 (241.87 s)\n",
            "40000: train acc = 0.9987, val acc = 0.9800, test acc = 0.9820, train loss = 0.0042, val loss = 0.1642, test loss = 0.1465 (242.44 s)\n",
            "40100: train acc = 0.9992, val acc = 0.9816, test acc = 0.9826, train loss = 0.0032, val loss = 0.1433, test loss = 0.1300 (243.07 s)\n",
            "40200: train acc = 0.9985, val acc = 0.9810, test acc = 0.9803, train loss = 0.0051, val loss = 0.1596, test loss = 0.1514 (243.80 s)\n",
            "40300: train acc = 0.9982, val acc = 0.9818, test acc = 0.9814, train loss = 0.0099, val loss = 0.1595, test loss = 0.1484 (244.33 s)\n",
            "40400: train acc = 0.9987, val acc = 0.9832, test acc = 0.9819, train loss = 0.0047, val loss = 0.1342, test loss = 0.1410 (244.90 s)\n",
            "40500: train acc = 0.9991, val acc = 0.9836, test acc = 0.9830, train loss = 0.0035, val loss = 0.1388, test loss = 0.1392 (245.56 s)\n",
            "40600: train acc = 0.9995, val acc = 0.9836, test acc = 0.9828, train loss = 0.0020, val loss = 0.1353, test loss = 0.1390 (246.29 s)\n",
            "40700: train acc = 0.9989, val acc = 0.9814, test acc = 0.9813, train loss = 0.0045, val loss = 0.1383, test loss = 0.1546 (246.80 s)\n",
            "40800: train acc = 0.9995, val acc = 0.9838, test acc = 0.9830, train loss = 0.0013, val loss = 0.1221, test loss = 0.1343 (247.37 s)\n",
            "40900: train acc = 0.9995, val acc = 0.9834, test acc = 0.9829, train loss = 0.0015, val loss = 0.1200, test loss = 0.1345 (248.02 s)\n",
            "41000: train acc = 0.9993, val acc = 0.9838, test acc = 0.9822, train loss = 0.0026, val loss = 0.1251, test loss = 0.1567 (248.75 s)\n",
            "41100: train acc = 0.9996, val acc = 0.9854, test acc = 0.9824, train loss = 0.0012, val loss = 0.1235, test loss = 0.1541 (249.25 s)\n",
            "41200: train acc = 0.9996, val acc = 0.9848, test acc = 0.9826, train loss = 0.0009, val loss = 0.1223, test loss = 0.1474 (249.81 s)\n",
            "41300: train acc = 0.9997, val acc = 0.9864, test acc = 0.9830, train loss = 0.0006, val loss = 0.1155, test loss = 0.1471 (250.45 s)\n",
            "41400: train acc = 0.9990, val acc = 0.9824, test acc = 0.9815, train loss = 0.0034, val loss = 0.1240, test loss = 0.1635 (251.18 s)\n",
            "41500: train acc = 0.9991, val acc = 0.9832, test acc = 0.9814, train loss = 0.0032, val loss = 0.1310, test loss = 0.1601 (251.67 s)\n",
            "41600: train acc = 0.9997, val acc = 0.9844, test acc = 0.9835, train loss = 0.0011, val loss = 0.1280, test loss = 0.1496 (252.23 s)\n",
            "41700: train acc = 0.9994, val acc = 0.9842, test acc = 0.9824, train loss = 0.0020, val loss = 0.1313, test loss = 0.1609 (252.90 s)\n",
            "41800: train acc = 0.9975, val acc = 0.9830, test acc = 0.9804, train loss = 0.0094, val loss = 0.1629, test loss = 0.1604 (253.61 s)\n",
            "41900: train acc = 0.9958, val acc = 0.9810, test acc = 0.9781, train loss = 0.0196, val loss = 0.1689, test loss = 0.1952 (254.11 s)\n",
            "42000: train acc = 0.9979, val acc = 0.9832, test acc = 0.9800, train loss = 0.0072, val loss = 0.1429, test loss = 0.1876 (254.67 s)\n",
            "42100: train acc = 0.9985, val acc = 0.9834, test acc = 0.9807, train loss = 0.0054, val loss = 0.1417, test loss = 0.1671 (255.31 s)\n",
            "42200: train acc = 0.9984, val acc = 0.9844, test acc = 0.9802, train loss = 0.0066, val loss = 0.1451, test loss = 0.1665 (256.03 s)\n",
            "42300: train acc = 0.9989, val acc = 0.9834, test acc = 0.9822, train loss = 0.0038, val loss = 0.1376, test loss = 0.1603 (256.54 s)\n",
            "42400: train acc = 0.9986, val acc = 0.9858, test acc = 0.9813, train loss = 0.0048, val loss = 0.1331, test loss = 0.1597 (257.10 s)\n",
            "42500: train acc = 0.9988, val acc = 0.9822, test acc = 0.9814, train loss = 0.0042, val loss = 0.1399, test loss = 0.1578 (257.75 s)\n",
            "42600: train acc = 0.9966, val acc = 0.9808, test acc = 0.9787, train loss = 0.0148, val loss = 0.1579, test loss = 0.1697 (258.47 s)\n",
            "42700: train acc = 0.9981, val acc = 0.9786, test acc = 0.9798, train loss = 0.0074, val loss = 0.1691, test loss = 0.1748 (258.98 s)\n",
            "42800: train acc = 0.9993, val acc = 0.9854, test acc = 0.9811, train loss = 0.0022, val loss = 0.1418, test loss = 0.1499 (259.54 s)\n",
            "42900: train acc = 0.9998, val acc = 0.9874, test acc = 0.9831, train loss = 0.0007, val loss = 0.1318, test loss = 0.1426 (260.17 s)\n",
            "43000: train acc = 0.9997, val acc = 0.9858, test acc = 0.9825, train loss = 0.0010, val loss = 0.1332, test loss = 0.1462 (260.88 s)\n",
            "43100: train acc = 0.9995, val acc = 0.9852, test acc = 0.9835, train loss = 0.0016, val loss = 0.1400, test loss = 0.1500 (261.38 s)\n",
            "43200: train acc = 0.9990, val acc = 0.9844, test acc = 0.9814, train loss = 0.0033, val loss = 0.1533, test loss = 0.1648 (261.93 s)\n",
            "43300: train acc = 0.9990, val acc = 0.9840, test acc = 0.9819, train loss = 0.0038, val loss = 0.1630, test loss = 0.1723 (262.55 s)\n",
            "43400: train acc = 0.9996, val acc = 0.9832, test acc = 0.9830, train loss = 0.0016, val loss = 0.1471, test loss = 0.1555 (263.26 s)\n",
            "43500: train acc = 0.9990, val acc = 0.9832, test acc = 0.9831, train loss = 0.0042, val loss = 0.1571, test loss = 0.1661 (263.77 s)\n",
            "43600: train acc = 0.9989, val acc = 0.9844, test acc = 0.9820, train loss = 0.0039, val loss = 0.1568, test loss = 0.1612 (264.32 s)\n",
            "43700: train acc = 0.9992, val acc = 0.9838, test acc = 0.9823, train loss = 0.0024, val loss = 0.1440, test loss = 0.1574 (264.94 s)\n",
            "43800: train acc = 0.9993, val acc = 0.9834, test acc = 0.9818, train loss = 0.0024, val loss = 0.1457, test loss = 0.1504 (265.65 s)\n",
            "43900: train acc = 0.9987, val acc = 0.9824, test acc = 0.9789, train loss = 0.0051, val loss = 0.1565, test loss = 0.1886 (266.13 s)\n",
            "44000: train acc = 0.9992, val acc = 0.9846, test acc = 0.9813, train loss = 0.0025, val loss = 0.1490, test loss = 0.1689 (266.69 s)\n",
            "44100: train acc = 0.9991, val acc = 0.9834, test acc = 0.9826, train loss = 0.0030, val loss = 0.1460, test loss = 0.1652 (267.32 s)\n",
            "44200: train acc = 0.9989, val acc = 0.9830, test acc = 0.9812, train loss = 0.0039, val loss = 0.1675, test loss = 0.1677 (268.04 s)\n",
            "44300: train acc = 0.9992, val acc = 0.9830, test acc = 0.9820, train loss = 0.0023, val loss = 0.1531, test loss = 0.1650 (268.53 s)\n",
            "44400: train acc = 0.9983, val acc = 0.9816, test acc = 0.9799, train loss = 0.0069, val loss = 0.1597, test loss = 0.1870 (269.08 s)\n",
            "44500: train acc = 0.9984, val acc = 0.9826, test acc = 0.9788, train loss = 0.0064, val loss = 0.1550, test loss = 0.1742 (269.73 s)\n",
            "44600: train acc = 0.9985, val acc = 0.9798, test acc = 0.9804, train loss = 0.0053, val loss = 0.1679, test loss = 0.1663 (270.43 s)\n",
            "44700: train acc = 0.9989, val acc = 0.9832, test acc = 0.9814, train loss = 0.0033, val loss = 0.1382, test loss = 0.1618 (270.92 s)\n",
            "44800: train acc = 0.9984, val acc = 0.9830, test acc = 0.9804, train loss = 0.0066, val loss = 0.1502, test loss = 0.1859 (271.46 s)\n",
            "44900: train acc = 0.9978, val acc = 0.9794, test acc = 0.9797, train loss = 0.0079, val loss = 0.1778, test loss = 0.2102 (272.09 s)\n",
            "45000: train acc = 0.9980, val acc = 0.9802, test acc = 0.9804, train loss = 0.0100, val loss = 0.1794, test loss = 0.1937 (272.80 s)\n",
            "45100: train acc = 0.9981, val acc = 0.9798, test acc = 0.9796, train loss = 0.0087, val loss = 0.1868, test loss = 0.1742 (273.28 s)\n",
            "45200: train acc = 0.9992, val acc = 0.9810, test acc = 0.9819, train loss = 0.0032, val loss = 0.1620, test loss = 0.1556 (273.82 s)\n",
            "45300: train acc = 0.9992, val acc = 0.9822, test acc = 0.9831, train loss = 0.0026, val loss = 0.1586, test loss = 0.1541 (274.45 s)\n",
            "45400: train acc = 0.9996, val acc = 0.9844, test acc = 0.9828, train loss = 0.0016, val loss = 0.1474, test loss = 0.1561 (275.14 s)\n",
            "45500: train acc = 0.9978, val acc = 0.9814, test acc = 0.9815, train loss = 0.0090, val loss = 0.1739, test loss = 0.1745 (275.68 s)\n",
            "45600: train acc = 0.9981, val acc = 0.9796, test acc = 0.9826, train loss = 0.0072, val loss = 0.1717, test loss = 0.1719 (276.25 s)\n",
            "45700: train acc = 0.9980, val acc = 0.9778, test acc = 0.9808, train loss = 0.0076, val loss = 0.1953, test loss = 0.1765 (276.88 s)\n",
            "45800: train acc = 0.9988, val acc = 0.9792, test acc = 0.9808, train loss = 0.0042, val loss = 0.1658, test loss = 0.1732 (277.58 s)\n",
            "45900: train acc = 0.9991, val acc = 0.9808, test acc = 0.9820, train loss = 0.0033, val loss = 0.1796, test loss = 0.1691 (278.09 s)\n",
            "46000: train acc = 0.9988, val acc = 0.9804, test acc = 0.9812, train loss = 0.0051, val loss = 0.1844, test loss = 0.1733 (278.65 s)\n",
            "46100: train acc = 0.9983, val acc = 0.9814, test acc = 0.9805, train loss = 0.0074, val loss = 0.1557, test loss = 0.1831 (279.29 s)\n",
            "46200: train acc = 0.9985, val acc = 0.9818, test acc = 0.9813, train loss = 0.0050, val loss = 0.1753, test loss = 0.1728 (279.99 s)\n",
            "46300: train acc = 0.9994, val acc = 0.9842, test acc = 0.9834, train loss = 0.0021, val loss = 0.1521, test loss = 0.1555 (280.49 s)\n",
            "46400: train acc = 0.9993, val acc = 0.9836, test acc = 0.9817, train loss = 0.0022, val loss = 0.1476, test loss = 0.1610 (281.04 s)\n",
            "46500: train acc = 0.9990, val acc = 0.9826, test acc = 0.9822, train loss = 0.0035, val loss = 0.1651, test loss = 0.1772 (281.66 s)\n",
            "46600: train acc = 0.9995, val acc = 0.9832, test acc = 0.9821, train loss = 0.0015, val loss = 0.1584, test loss = 0.1695 (282.39 s)\n",
            "46700: train acc = 0.9995, val acc = 0.9806, test acc = 0.9833, train loss = 0.0018, val loss = 0.1688, test loss = 0.1624 (282.87 s)\n",
            "46800: train acc = 0.9999, val acc = 0.9832, test acc = 0.9844, train loss = 0.0006, val loss = 0.1610, test loss = 0.1468 (283.43 s)\n",
            "46900: train acc = 0.9999, val acc = 0.9814, test acc = 0.9844, train loss = 0.0004, val loss = 0.1559, test loss = 0.1477 (284.09 s)\n",
            "47000: train acc = 0.9996, val acc = 0.9816, test acc = 0.9829, train loss = 0.0009, val loss = 0.1523, test loss = 0.1509 (284.82 s)\n",
            "47100: train acc = 0.9991, val acc = 0.9816, test acc = 0.9816, train loss = 0.0037, val loss = 0.1610, test loss = 0.1719 (285.30 s)\n",
            "47200: train acc = 0.9996, val acc = 0.9822, test acc = 0.9830, train loss = 0.0013, val loss = 0.1599, test loss = 0.1587 (285.85 s)\n",
            "47300: train acc = 0.9990, val acc = 0.9812, test acc = 0.9822, train loss = 0.0041, val loss = 0.1693, test loss = 0.1583 (286.48 s)\n",
            "47400: train acc = 0.9996, val acc = 0.9814, test acc = 0.9818, train loss = 0.0016, val loss = 0.1473, test loss = 0.1559 (287.19 s)\n",
            "47500: train acc = 0.9990, val acc = 0.9806, test acc = 0.9814, train loss = 0.0038, val loss = 0.1597, test loss = 0.1706 (287.67 s)\n",
            "47600: train acc = 0.9991, val acc = 0.9798, test acc = 0.9820, train loss = 0.0041, val loss = 0.1589, test loss = 0.1621 (288.23 s)\n",
            "47700: train acc = 0.9992, val acc = 0.9826, test acc = 0.9825, train loss = 0.0038, val loss = 0.1378, test loss = 0.1616 (288.85 s)\n",
            "47800: train acc = 0.9993, val acc = 0.9834, test acc = 0.9824, train loss = 0.0026, val loss = 0.1451, test loss = 0.1569 (289.55 s)\n",
            "47900: train acc = 0.9986, val acc = 0.9804, test acc = 0.9819, train loss = 0.0048, val loss = 0.1687, test loss = 0.1539 (290.06 s)\n",
            "48000: train acc = 0.9992, val acc = 0.9820, test acc = 0.9828, train loss = 0.0030, val loss = 0.1576, test loss = 0.1476 (290.61 s)\n",
            "48100: train acc = 0.9996, val acc = 0.9832, test acc = 0.9825, train loss = 0.0011, val loss = 0.1566, test loss = 0.1569 (291.24 s)\n",
            "48200: train acc = 0.9998, val acc = 0.9832, test acc = 0.9829, train loss = 0.0008, val loss = 0.1475, test loss = 0.1523 (291.96 s)\n",
            "48300: train acc = 0.9998, val acc = 0.9842, test acc = 0.9845, train loss = 0.0004, val loss = 0.1390, test loss = 0.1449 (292.45 s)\n",
            "48400: train acc = 0.9999, val acc = 0.9832, test acc = 0.9842, train loss = 0.0004, val loss = 0.1346, test loss = 0.1442 (293.00 s)\n",
            "48500: train acc = 0.9992, val acc = 0.9824, test acc = 0.9810, train loss = 0.0038, val loss = 0.1646, test loss = 0.1730 (293.63 s)\n",
            "48600: train acc = 0.9991, val acc = 0.9822, test acc = 0.9810, train loss = 0.0031, val loss = 0.1480, test loss = 0.1570 (294.33 s)\n",
            "48700: train acc = 0.9989, val acc = 0.9840, test acc = 0.9817, train loss = 0.0043, val loss = 0.1465, test loss = 0.1672 (294.81 s)\n",
            "48800: train acc = 0.9981, val acc = 0.9812, test acc = 0.9804, train loss = 0.0088, val loss = 0.1544, test loss = 0.1654 (295.37 s)\n",
            "48900: train acc = 0.9978, val acc = 0.9830, test acc = 0.9803, train loss = 0.0112, val loss = 0.1688, test loss = 0.1850 (296.00 s)\n",
            "49000: train acc = 0.9982, val acc = 0.9830, test acc = 0.9803, train loss = 0.0057, val loss = 0.1729, test loss = 0.1735 (296.70 s)\n",
            "49100: train acc = 0.9982, val acc = 0.9820, test acc = 0.9790, train loss = 0.0078, val loss = 0.1580, test loss = 0.1772 (297.19 s)\n",
            "49200: train acc = 0.9991, val acc = 0.9832, test acc = 0.9814, train loss = 0.0030, val loss = 0.1399, test loss = 0.1593 (297.76 s)\n",
            "49300: train acc = 0.9983, val acc = 0.9834, test acc = 0.9797, train loss = 0.0058, val loss = 0.1493, test loss = 0.1567 (298.41 s)\n",
            "49400: train acc = 0.9995, val acc = 0.9830, test acc = 0.9834, train loss = 0.0015, val loss = 0.1346, test loss = 0.1435 (299.11 s)\n",
            "49500: train acc = 0.9995, val acc = 0.9824, test acc = 0.9829, train loss = 0.0014, val loss = 0.1354, test loss = 0.1507 (299.61 s)\n",
            "49600: train acc = 0.9995, val acc = 0.9826, test acc = 0.9821, train loss = 0.0015, val loss = 0.1313, test loss = 0.1545 (300.15 s)\n",
            "49700: train acc = 0.9995, val acc = 0.9824, test acc = 0.9813, train loss = 0.0018, val loss = 0.1360, test loss = 0.1644 (300.80 s)\n",
            "49800: train acc = 0.9989, val acc = 0.9828, test acc = 0.9810, train loss = 0.0032, val loss = 0.1482, test loss = 0.1716 (301.51 s)\n",
            "49900: train acc = 0.9996, val acc = 0.9820, test acc = 0.9833, train loss = 0.0017, val loss = 0.1396, test loss = 0.1564 (302.03 s)\n",
            "50000: train acc = 0.9994, val acc = 0.9840, test acc = 0.9812, train loss = 0.0023, val loss = 0.1389, test loss = 0.1589 (302.58 s)\n",
            "50100: train acc = 0.9993, val acc = 0.9826, test acc = 0.9826, train loss = 0.0023, val loss = 0.1517, test loss = 0.1629 (303.21 s)\n",
            "50200: train acc = 0.9980, val acc = 0.9822, test acc = 0.9808, train loss = 0.0072, val loss = 0.1641, test loss = 0.1822 (303.93 s)\n",
            "50300: train acc = 0.9989, val acc = 0.9828, test acc = 0.9809, train loss = 0.0036, val loss = 0.1516, test loss = 0.1727 (304.44 s)\n",
            "50380: train acc = 0.9991, val acc = 0.9834, test acc = 0.9810, train loss = 0.0026, val loss = 0.1345, test loss = 0.1725 (304.95 s)\n",
            "\n",
            "       Exit code:  0\n",
            "       Wall time:  5:11.660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zlUMVaXRY9KH",
        "outputId": "f3f130af-13c8-49fb-9549-df4721ee209e"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/deconstructing-lottery-tickets'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgCbP2IpYldy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}